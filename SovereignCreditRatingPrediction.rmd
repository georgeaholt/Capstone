---
title: "Sovereign Credit Rating Prediction"
author: "George Holt (Riskfree)"
date: "30 December 2020"
output:
  bookdown::pdf_document2:
    toc: yes
    toc_depth: '4'
    number_sections: yes
    fig_width: 7
    fig_height: 3.5
    fig_caption: yes
    highlight: tango
    extra_dependencies: float
    tables: true
    header-includes:
    - \usepackage{float}
    - \floatplacement{figure}{H}
    - \lstset{basicstyle=\small, breaklines=true}
    pandoc_args: --listings
  pdf_document:
    toc: yes
    toc_depth: '4'
  html_document:
    number_sections: yes
subtitle: 'PH125.9x Data Science: Capstone'
bibliography: Untitled_files/reprex.bib
---
```{r Download-BibTex-References, warning = FALSE, echo = FALSE}
dir.create("Untitled_files")
download.file("https://raw.githubusercontent.com/georgeaholt/Capstone/main/SovereignCreditRatingPredictionreferences.bib",
              "Untitled_files/reprex.bib")
```

```{r Install-Required-Packages, echo = FALSE, include = FALSE}
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(stringr)) install.packages("stringr", repos = "http://cran.us.r-project.org")
if(!require(lubridate)) install.packages("lubridate", repos = "http://cran.us.r-project.org")
if(!require(purrr)) install.packages("purrr", repos = "http://cran.us.r-project.org")
if(!require(matrixStats)) install.packages("matrixStats", repos = "http://cran.us.r-project.org")
if(!require(e1071)) install.packages("e1071", repos = "http://cran.us.r-project.org")
if(!require(knitr)) install.packages("knitr", repos = "http://cran.us.r-project.org")
if(!require(rvest)) install.packages("rvest", repos = "http://cran.us.r-project.org")
if(!require(dplyr)) install.packages("dplyr", repos = "http://cran.us.r-project.org")
if(!require(kableExtra)) install.packages("kableExtra", repos = "http://cran.us.r-project.org")
if(!require(WDI)) install.packages("WDI", repos = "http://cran.us.r-project.org")
if(!require(IMFData)) install.packages("IMFData", repos = "http://cran.us.r-project.org")
if(!require(imfr)) install.packages("imfr", repos = "http://cran.us.r-project.org")
if(!require(RColorBrewer)) install.packages("RColorBrewer", repos = "http://cran.us.r-project.org")
if(!require(MASS)) install.packages("MASS", repos = "http://cran.us.r-project.org")
if(!require(ordinal)) install.packages("ordinal", repos = "http://cran.us.r-project.org")
if(!require(ordinalForest)) install.packages("ordinalForest", repos = "http://cran.us.r-project.org")
if(!require(psych)) install.packages("psych", repos = "http://cran.us.r-project.org")
if(!require(pander)) install.packages("pander", repos = "http://cran.us.r-project.org")
if(!require(jsonlite)) install.packages("jsonlite", repos = "http://cran.us.r-project.org")
if(!require(readr)) install.packages("readr", repos = "http://cran.us.r-project.org")
if(!require(httr)) install.packages("httr", repos = "http://cran.us.r-project.org")
if(!require(vtreat)) install.packages("vtreat", repos = "http://cran.us.r-project.org")
if(!require(vcd)) install.packages("vcd", repos = "http://cran.us.r-project.org")
if(!require(ModelMetrics)) install.packages("ModelMetrics", repos = "http://cran.us.r-project.org")
if(!require(gridExtra)) install.packages("gridExtra", repos = "http://cran.us.r-project.org")
if(!require(cowplot)) install.packages("cowplot", repos = "http://cran.us.r-project.org")
if(!require(broom)) install.packages("broon", repos = "http://cran.us.r-project.org")
if(!require(irr)) install.packages("irr", repos = "http://cran.us.r-project.org")
if(!require(ggmosaic)) install.packages("ggmosaic", repos = "http://cran.us.r-project.org")

```
```{r Load-Libraries, echo = FALSE, include = FALSE}
# Load required libraries
library(tidyverse)
library(caret)
library(data.table)
library(stringr)
library(lubridate)
library(purrr)
library(matrixStats)
library(e1071)
library(knitr)
library(rvest)
library(dplyr, warn.conflicts = FALSE)
library(kableExtra)
library(WDI)
library(IMFData)
library(imfr)
library(RColorBrewer)
library(MASS)
library(ordinal)
library(ordinalForest)
library(psych)
library(pander)
library(jsonlite)
library(readr)
library(httr)
library(vtreat)
library(vcd)
library(ModelMetrics)
library(gridExtra)
library(cowplot)
library(broom)
library(irr)
library(ggmosaic)
```
```{r, Set-Options, include = FALSE}
options(tinytex.verbose = TRUE)
options(dplyr.summarise.inform = FALSE)
```
```{r Define-Chunk-Timer, echo = FALSE}
knitr::knit_hooks$set(time_it = local({
  now <- NULL
  function(before, options) {
    if (before) {
      # record the current time before each chunk
      now <<- Sys.time()
    } else {
      # calculate the time difference after a chunk
      res <- difftime(Sys.time(), now)
      # return a character string to show the time
      paste("Time for this code chunk to run:", res)
    }
  }
}))
```

# Introduction

Can sovereign credit ratings be predicted using current and historical economic and other data about the sovereign? What are the economic and financial variables that best predict sovereign credit ratings? How reliable are the sovereign credit rating predictions given the available economic and financial data? These are some of the questions addressed in the research reviewed in this report.

Credit ratings are ordered categorical assessments of the credit quality of an entity, such as a corporation, that indicate the ability of the entity to satisfy its bond and other debt obligations in a timely fashion. Credit ratings can be assigned to entities by any observer, but the most widely published and respected credit ratings are assigned by three organizations: Moody's Investors Service ("Moodys"), Standard and Poors Corporation ("S&P"), and Fitch Ratings ("Fitch"). These three rating agencies are recognized by securities and banking regulatory authorities as Nationally Recognized Statistical Rating Organizations ("NRSROs") or External Credit Assessment Institutions ("ECAIs") as authorities on credit quality, typically as part of the authorities credit risk regulations.

Credit ratings are useful to investors in fixed income debt instruments, such as bonds issued by a rated entity or loans made to a rated entity. Credit ratings are useful to investors as indicators of the relative credit quality of different debt instruments held in their portfolios, which assists investors in diversifying the credit risk of the portfolios. Credit ratings of rated entities also affect market yield spreads between debt instruments issued by different entities, e.g. between corporate bonds and U.S. Treasury securities, and therefore affect the pricing of those instruments. See for example [@grothe}. As noted above, credit ratings are also used by banking organizations to calculate risk capital requirements imposed by bank regulatory authorities.

Each of the rating agencies has established a methodology for determining the appropriate credit rating category of an entity at a particular point in time. Generally, these methodologies are based on objective measures of an entity's ability to satisfy its bond and other debt obligations, such as its income and assets, but the selection of a particular rating category is also based upon human judgment, which means that the rating assignment is partly subjective. While the labels for rating categories differ somewhat across the agencies, the categories for all agencies can be grouped into a consistent grading hierarchy, and the rating categories for each agency can be rank ordered according to increasing credit risk.

The agencies generally provide credit ratings for four types of debt obligations: long-term foreign currency, short-term foreign currency, long-term local currency, and short-term local currency, where long-term means over one year and short-term under one year, and foreign currency means obligations denominated in the currency of a country other than the sovereign obligor and local currency means obligations denominated in the currency of the sovereign obligor. In this report, only long-term foreign currency credit ratings are considered, since they are the most commonly used sovereign credit ratings. The grading hierarchy and rank ordering of credit rating categories for the three rating agencies are presented in Table \ref{tab:Display-Credit-Rating-Descriptions}.

```{r Set-Up-ISO-Country-Codes, message = FALSE, echo = FALSE}
# Set up sovereign iso codes
country_codes_url <- "https://raw.githubusercontent.com/georgeaholt/Capstone/main/Country%20Codes.csv"
iso_country_codes <- read.csv(country_codes_url)
colnames(iso_country_codes) <- c("country", "iso2_code")
```
```{r Download-Website-Ratings-HTML, echo = FALSE}
# Download the ratings page HTML from the website
country_economics <- "https://countryeconomy.com"
country_economics_ratings <- "https://countryeconomy.com/ratings"
country_economics_html <- read_html(country_economics_ratings)
```
```{r Access-Country-Listing-Table, echo = FALSE}
# Access the country listing table in the webpage
table_body <- country_economics_html %>% html_node("table") %>% html_node("tbody")
```
```{r Access-Country-Listing-Table-Rows, echo = FALSE}
# Access the rows in the country listing table
table_rows_html <- table_body %>% html_nodes("tr")
```
```{r Initialize-Country-Links, echo = FALSE}
# Initialize a list of relative urls for all countries
country_links <- tibble(country = character(), rel_url = character())
```
```{r Construct-Country-Links-List, warnings = FALSE, echo = FALSE}
# Iterate over the rows in the country list to construct a list of country links for all countries 
# that contains the country name and the relative urls for each country. Print the number of 
# countries and the first 10 country links.
for (row_value in table_rows_html) {
  row_string <- as.character(row_value)
  relative_url <- str_sub(str_extract(row_string, "/.+\""), 1, -2)
  country_name <- sub(" \\[", "", sub("\">", "", str_extract(row_string, "\">.+\\[")))
  country_links <- rbind(country_links, c(country_name, relative_url))
}
num_countries <- dim(country_links)[1]
country_relative_urls <- as_tibble(country_links)
colnames(country_relative_urls) <- c("country", "relurl")
```
```{r Extract-Long-Term-Rating-Descriptions, warnings = FALSE, echo = FALSE}
# The following code extracts the long-term credit rating descriptions for the credit rating
# agencies. This information is contained on each country webpage, so only the first country 
# webpage needs to be retrieved. 
# Get the country url for the first country and download the html code for the country webpage
country_url <- paste(country_economics,country_links[1, 2], sep = "")
country_html <- read_html(country_url)
# Find the rating agency tables in the country ratings webpage
country_tables <- country_html %>% html_nodes("table")
# Get the rating category descriptions for the rating agencies
long_term_rating_description_rows <- country_tables[4] %>% html_nodes("tbody") %>% html_nodes("tr")
# Set up an empty credit rating description tibble
credit_rating_descriptions <- tibble(Grade = character(),
                                     Moodys = character(),
                                     SandP = character(),
                                     Fitch = character())
# Iterate over the rows in the rating description table
for (description in 1:length(long_term_rating_description_rows)) {
  # Determine whether the "rowspan" attribute value applies to the row
  rowspan <- str_detect(as.character(long_term_rating_description_rows[description]), "rowspan=\".+\" ")
  # Determine whether the "class" attribute value applies to the row
  classrow <- str_detect(as.character(long_term_rating_description_rows[description]), "class=\"wborder")
  # Extracting rating descriptions for each row in the table
  long_term_rating_description_row_data_nodes <- long_term_rating_description_rows[description] %>% html_nodes("td")
  # Extract the rating items from the table row
  rating_items <- character()
  # If the row is a "rowspan" or "class row, it will contain 4 items
  if (rowspan | classrow) {
    for (item in 1:length(long_term_rating_description_row_data_nodes)) {
      rating_item <- sub("<", "", sub(">", "", 
                                      str_extract(as.character(long_term_rating_description_row_data_nodes[item]), ">.*<")))
      rating_items <- append(rating_items, rating_item)
    } 
    # Otherwise, the row will start with an empty cell followed by 3 items
  } else {
    rating_item <- " "
    rating_items <- append(rating_items, rating_item)
    for (item in 1:length(long_term_rating_description_row_data_nodes)) {
      rating_item <- sub("<", "", sub(">", "", 
                                      str_extract(as.character(long_term_rating_description_row_data_nodes[item]), ">.*<")))
      rating_items <- append(rating_items, rating_item)
    }
  }
  row_tibble <- tibble(Grade = rating_items[1], Moodys = rating_items[2], SandP = rating_items[3], Fitch = rating_items[4])
  # Append the items to the credit rating description tibble
  credit_rating_descriptions <- rbind(credit_rating_descriptions, row_tibble)
}
```
```{r Display-Credit-Rating-Descriptions, echo = FALSE}
#credit_rating_descriptions <- readRDS("CreditRatingDescriptions.rds")
credit_rating_descriptions <- credit_rating_descriptions %>% 
  mutate(Grade = ifelse(str_detect(Grade, "br>"), sub("<", "", sub("br>", "", Grade)), Grade))
knitr::kable(credit_rating_descriptions, caption = "Long-Term Credit Rating Categories", format = "latex", booktabs = TRUE)
```
```{r Define-Agency-Rating-Order, echo = FALSE}
# Define the credit rating category order for each rating agency
moodys_rating_list <- credit_rating_descriptions$Moodys[!(credit_rating_descriptions$Moodys == "")]
moodys_rating_categories <- factor(moodys_rating_list, levels = moodys_rating_list, ordered = TRUE)
moodys_rating_order <- 1:length(moodys_rating_categories)
names(moodys_rating_order) <- moodys_rating_categories
sandp_rating_list <- credit_rating_descriptions$SandP[!(credit_rating_descriptions$SandP == "")]
sandp_rating_categories <- factor(sandp_rating_list, levels = sandp_rating_list, ordered = TRUE)
sandp_rating_order <- 1:length(sandp_rating_categories)
names(sandp_rating_order) <- sandp_rating_categories
fitch_rating_list <- credit_rating_descriptions$Fitch[!(credit_rating_descriptions$Fitch == "")]
fitch_rating_categories <- factor(fitch_rating_list, levels = fitch_rating_list, ordered = TRUE)
fitch_rating_order <- 1:length(fitch_rating_categories)
names(fitch_rating_order) <- fitch_rating_categories
```
This table shows that Moody's has `r length(moodys_rating_categories)` rating categories, Standard & Poors has `r length(sandp_rating_categories)` rating categories, and Fitch has `r length(fitch_rating_categories)` rating categories.

One class of entities that is covered by the rating agencies is sovereign governments, which are generally the national governments of various countries. The ability to satisfy debt obligations differs among corporations, sovereigns, and other entities, so the rating agencies methodologies for sovereigns differ from the methodologies for other types of obligors. Considering these differences, the rating agencies list numerous economic, social, and political factors that underlie their sovereign credit rating assessments in their statements on rating criteria.

In the first systematic analysis of the determinants and impact of the sovereign credit ratings assigned by the credit ratings agencies, Richard Cantor and Frank Packer of the Federal Reserve Bank of New York identified eight variables that are repeatedly cited in rating agency reports as determinants of sovereign ratings. These variables are (see [@cantor-packer]):

  * *Per capita income*. Sovereigns with a higher per capita income have a larger potential tax base a greater ability to repay debt, so they should have a higher credit rating. This variable can also serve as a proxy for the level of political stability and other important factors.

  * *GDP growth*. A relatively high rate of economic growth suggests that a sovereign’s existing debt burden will become easier to service over time.

  * *Inflation*. A high rate of inflation points to structural problems in the government’s finances. When a government appears unable or unwilling to pay for current budgetary expenses through taxes or debt issuance, it must resort to inflationary money finance. Public dissatisfaction with inflation may in turn lead to political instability.
  
  * *Fiscal balance*. A large government deficit absorbs private domestic savings and suggests that a government lacks the ability or will to tax its citizenry to cover current expenses or to service its debt, while a government surplus indicates the ability to tax or reduce expenses to service debt.

  * *External balance*. A large current account deficit indicates that the public and private sectors together rely heavily on funds from abroad. Current account deficits that persist result in growth in foreign indebtedness, which may become unsustainable over time.
  
  * *External debt*. A higher debt burden should correspond to a higher risk of default. The weight of the burden increases as a country’s foreign currency debt rises relative to its foreign currency earnings (exports).
  
  * *Economic development*. Countries that are classified as economically developed, are expected to have a higher credit rating.  They are perceived to have attained a certain minimum threshold of economic development for which default is very unlikely.  In addition, these countries are often strongly integrated with the world economy, such that a default is less likely, as foreign creditors can more easily disrupt trade or seize assets abroad in case of default. A proxy for this minimum income or development level is a simple indicator variable noting whether or not a country is classified as industrialized by the International Monetary Fund.

* *Default history*. Other things being equal, a country that has defaulted on debt in the recent past is widely perceived as a high credit risk. Both theoretical considerations of the role of reputation in sovereign debt (see [@eaton]) and related empirical evidence indicate that defaulting sovereigns suffer a severe decline in their standing with creditors (see [@ozler]). Credit reputation can be incorporated by using an indicator variable that notes whether or not a country has defaulted on its international bank debt since 1970.

Several studies of sovereign credit rating determinants have been conducted subsequent to the research performed by Cantor and Packer. (See, e.g., [@valle-marin]). These studies typically show that many of the economic and financial indicators listed above are important determinants of the credit ratings assigned to sovereigns. This report investigates whether the credit rating assessments of the credit rating agencies for sovereigns can be predicted using surrogates for the variables outlined by Cantor and Packer using machine learning models.

The discussion above provides some background on sovereign credit ratings and the observable variables that credit rating agencies use to assign credit ratings of sovereign obligors at various points in time. In the next section, the methodology for obtaining information about sovereign credit ratings and the economic and financial variables suggested as determining sovereign credit ratings is discussed. This section discusses both current and historical credit ratings as well as the credit rating actions upon which the historical credit ratings are based. Web scraping technology is employed to obtain the current rating and credit rating action data, which is subsequently analyzed and converted to historical time series of sovereign credit ratings.

The next section also discusses the sources for the economic and financial data suggested as determining sovereign credit ratings. Most of this data is obtained from databases maintained by the World Bank (IBRD) and the International Monetary Fund (IMF). This economic and financial data is downloaded from these databases as *.csv* files that are retained in a *GitHub* repository, and these files are accessed using the R language *read_csv()* function to create tibbles (data frames).

The following section develops modeling approaches used to estimate relationships between sovereign credit ratings and economic and financial indicators for sovereigns. These modeling approaches are applied to random training subsets of the historical observations for each agency's ratings to estimate model parameters, and the parameter estimates and other statistics for each fitted model are examined. The resulting fitted model for each agency is then used to predict credit ratings given a random test subset of associated indicator values that is a complement to the training observation subset. The resulting predicted credit ratings are displayed and compared to the actual historical credit ratings for each model.

In the next section, the predictive performance of each of the agency credit rating models is evaluated. The predictive performance of a model is measured in alternative ways: (i) whether the model predicts the same credit rating as was assigned by the rating agency, and (ii) whether the model predicts a credit rating that is the same or close to the credit rating assigned by the rating agency. In the latter case, alternative approaches to measuring the distance between different credit rating categories are applied. These performance measures provide a means of evaluating the ability of a model to predict credit ratings, and if so, how well each model predicts ratings similar to actual ratings.

The final section of this report summarizes the results of the model development and evaluation process and also offers conclusions and provides suggestions for further research on sovereign credit rating prediction.

# Methodology and Analysis

In this section, sources of sovereign credit rating information are identified, and approaches to extracting this information from the sources are discussed. Descriptive statistics and charts for current sovereign credit ratings are produced. The results show that sovereign credit rating assessments are not uniformly distributed across each agency's credit rating categories. Instead, a small group of sovereigns is assigned each agency's highest rating categories, and there are a substantial number of sovereigns that are assigned to each agency's lower rating categories.

Current sovereign credit ratings alone are insufficient to develop predictive models, since only about 140 sovereigns have current credit ratings. Consequently, historical credit ratings for sovereigns must also be acquired to provide sufficient observations to develop predictive models. However, historical credit rating series for sovereigns are not readily available, and the historical series must be constructed from information about historical credit rating actions taken by each agency. (A credit rating action is an announcement by a rating agency that is the result of a review of a sovereign indicating the current status of the sovereign's rating and whether it changes the credit rating category for the sovereign.) Thus, this report describes the process of obtaining the histories of credit rating actions for each sovereign and for converting these actions into a historical series of credit ratings. This process results in an annual time series of historical credit rating category assessments by each rating agency for each sovereign.

This section also considers sources for economic and financial indicators that are considered determinants of sovereign credit ratings. Several of the indicators that were identified by Cantor and Packer are discussed, and the sources of these indicators are explored. Since predictive models for both current and historical credit ratings are developed, a history of each indicator is also required to estimate the relationship between indicator values and ratings. Consequently, the report describes the process for obtaining the time series of each indicator over a time interval consistent with the credit rating histories.

The next part of this section develops models for predicting sovereign credit ratings. Earlier research on sovereign credit ratings used traditional linear regression models for this purpose, but there are several theoretical and practical issues with this approach. To address these issues, this report develops two predictive models for sovereign credit ratings that employ machine learning techniques. The first modeling approach is called *Ordinal Forest Classification*, which is similar to the random forest models used for regression, and the second modeling approach is *Linear Discriminant Analysis*. Each of these modeling approaches is used to train a sovereign credit rating prediction model for each of the rating agencies. The training process uses a randomly-selected subset of observations of historical credit ratings for each rated sovereign and associated economic and financial indicator values. Each model that results from this process is then applied to a complementary randomly-selected subset of observations of historical economic and financial indicator values associated with the sovereigns to produce predicted credit ratings for each sovereign during each year. The predicted ratings for each sovereign, rating agency, and year are then compared to actual ratings, and these results are summarized in confusion matrices and displayed graphically in mosaic charts.

The final part of this section considers some metrics for measuring the predictive performance of ordinal classification models such as the sovereign credit rating prediction models developed in this report. In addition to traditional *Percentage Observed Agreement*, these metrics include three variants of Cohen's *kappa*, Kendall's *Coefficient of Concordance*, and Spearman's *Average Rank Correlation*. Each of these metrics is applied to the predictions from the models for each rating agency to obtain the desired statistics, and the performance results are presented and summarized.

## Sovereign Credit Ratings

Analysis of sovereign credit ratings depends upon observations of current credit ratings as well as historical credit rating behavior, which consists of credit rating actions for sovereign entities over some historical time period. Each credit rating agency publishes current credit ratings and maintains a history of its credit rating actions, but accessing this data directly from each agency is not necessarily the most convenient method of collecting the data.

After investigating the potential sources of credit rating information, the internet website *countryeconomy*.com was identified as a more convenient source, since sovereign credit ratings and historical rating actions for all three rating agencies are available there. The *countryeconomy* website also offers a variety of additional economic and financial data for each country, so it is also convenient source for that information. The website claims to collect data from a variety of reputable sources, such as the credit rating agencies, the International Monetary Fund, The World Bank, and the central banks of various countries, but there may be differences between the website data and the original source data that have not been investigated while performing this analysis. Investigation of any differences is the subject of future research, so this analysis will assume that the data is consistent with the original source data.

To acquire the current credit ratings and historical credit rating action data from the *countryeconomy.com* website, a so-called web scraping process was developed that takes the *html* content for webpages and extracts the credit ratings and credit rating actions from those webpages. For purposes of this analysis, a main webpage containing a list of countries and current rating information and links to country specific webpages and a collection of webpages containing the historical credit rating actions for each country were the primary sources of the credit rating data. The process employed to perform web scraping involves downloading the *html* text, applying various functions in the *rvest* web scraping package to access nodes in the *html* text, using regular expression string functions to extract the rating information from the nodes, and assembling the rating information into data structures used in analysis.

```{r Define-Credit_Rating_Agency-Labels, echo = FALSE}
# Define labels for the three credit rating agencies
agencies <- c('Moodys','SandP','Fitch')
```
```{r Create-Current-Ratings-Tibble, echo = FALSE}
# Create an empty current long-term credit ratings tibble
current_sovereign_ratings <- tibble(country = character(), moodys = character(), sandp = character(), fitch = character())
colnames(current_sovereign_ratings) <- c("country", "moodys", "sandp", "fitch")
```
```{r Extract-Current-Country-Ratings, echo = FALSE}
# Get html text for all countries
country_html <- table_rows_html %>% 
  html_nodes("td")
# Iterate over the rows in the country list to extract the current country long-term credit ratings
for (i in 1: length(country_html)) {   
  if ((i %% 4) == 1) {
    country_label <- sub("\\[", "", sub("\">", "", str_extract(as.character(country_html[i]), "\">.+\\[")))
    }
  else
  if ((i %% 4) == 2) {
    agency_rating_1 <- sub(" </", "", sub("left\"> ", "", str_extract(as.character(country_html[i]), "left\">.+</")))
    }
  else
  if ((i %% 4) == 3) {
    agency_rating_2 <- sub(" </", "", sub("left\"> ", "", str_extract(as.character(country_html[i]), "left\">.+</")))
    }
  else
  if ((i %% 4) == 0) {
    agency_rating_3 <- sub(" </", "", sub("left\"> ", "", str_extract(as.character(country_html[i]), "left\">.+</")))
    current_sovereign_ratings <- rbind(current_sovereign_ratings, c(country_label, agency_rating_1, agency_rating_2, agency_rating_3))
    colnames(current_sovereign_ratings) <- c("country", "Moodys", "SandP", "Fitch")
  }
}
```
After performing the web scraping process, there are `r length(current_sovereign_ratings$country)` sovereigns currently rated by one or more rating agencies. These sovereigns are shown in Table \ref{tab:Create-List-of-Rated-Sovereigns}.


```{r Create-List-of-Rated-Sovereigns, echo = FALSE}
# Create list of rated sovereigns and display the list
current_sovereign_ratings_countries_A <- current_sovereign_ratings$country[1:48]
current_sovereign_ratings_countries_B <- current_sovereign_ratings$country[49:96]
current_sovereign_ratings_countries_C <- current_sovereign_ratings$country[97:144]
current_sovereign_ratings_countries_tibble <- tibble(Sovereigns = current_sovereign_ratings_countries_A, 
                                                     Sovereigns. = current_sovereign_ratings_countries_B, 
                                                     Sovereigns.. = current_sovereign_ratings_countries_C)
knitr::kable(current_sovereign_ratings_countries_tibble, caption = "Rated Sovereigns", format = "latex", booktabs = TRUE) %>% 
      kable_styling(latex_options = c("striped", "HOLD_position"), font_size = 8)
```


### Current Sovereign Credit Ratings

The current sovereign credit ratings are the cumulative result of credit rating actions taken by the rating agencies over the time period covered by the credit rating actions. Moody's currently has credit ratings for `r sum(!is.na(current_sovereign_ratings$Moodys))` countries, Standard & Poors currently has credit ratings for `r sum(!is.na(current_sovereign_ratings$SandP))` countries, and  Fitch currently has credit ratings for `r sum(!is.na(current_sovereign_ratings$Fitch))` countries. Credit rating assessments are not uniformly distributed across each agency's rating categories. This is demonstrated by histograms showing the number of countries in each Moody's rating category in Figure \@ref(fig:Display-Number-Of-Ratings-by-Rating-Category-Moodys), the number of countries in each Standard & Poors rating category in Figure \@ref(fig:Display-Number-Of-Ratings-by-Rating-Category-SandP), and the number of countries in each Fitch rating category in Figure \@ref(fig:Display-Number-Of-Ratings-by-Rating-Category-Fitch).


```{r Display-Number-Of-Ratings-by-Rating-Category-Moodys, fig.cap = "**Number of Sovereigns by Moody's Rating Category**", echo = FALSE}
# Display number of ratings by rating category for Moodys in a figure
moodys_current_ratings <- current_sovereign_ratings$Moodys[!is.na(current_sovereign_ratings$Moodys)]
moodys_current_ratings_table <- table(moodys_current_ratings)
moodys_current_ratings_categories <- names(moodys_current_ratings_table)
moodys_current_ratings_index <- moodys_rating_order[names(moodys_current_ratings_table)]
moodys_current_ratings_counts <- as.integer(moodys_current_ratings_table)
moodys_current_ratings_tibble <- tibble(rating_categories = moodys_current_ratings_categories, 
                                       rating_index = moodys_current_ratings_index, 
                                       rating_count = moodys_current_ratings_counts) %>% 
                                    arrange(rating_index)
moodys_current_ratings_tibble %>% 
  arrange(rating_index) %>% 
  ggplot(aes(reorder(rating_categories, rating_index), rating_count)) +
    geom_col(width = 0.5, fill="lightblue") +
    xlab("Moodys Rating Categpry") +
    ylab("Number of Sovereigns") +
    ylim(0, 15) +
    scale_fill_brewer() +
    theme(axis.text.x = element_text(angle = 45, hjust=1))
```


```{r Display-Number-Of-Ratings-by-Rating-Category-SandP, fig.cap = "**Number of Sovereigns by Standard & Poors Rating Category**", echo = FALSE}
# Display number of ratings by rating category for S and P in a figure
sandp_current_ratings <- current_sovereign_ratings$SandP[!is.na(current_sovereign_ratings$SandP)]
sandp_current_ratings_table <- table(sandp_current_ratings)
sandp_current_ratings_categories <- names(sandp_current_ratings_table)
sandp_current_ratings_index <- sandp_rating_order[names(sandp_current_ratings_table)]
sandp_current_ratings_counts <- as.integer(sandp_current_ratings_table)
sandp_current_ratings_tibble <- tibble(rating_categories = sandp_current_ratings_categories, 
                                       rating_index = sandp_current_ratings_index, 
                                       rating_count = sandp_current_ratings_counts) %>% 
                                    arrange(rating_index)
sandp_current_ratings_tibble %>% 
  arrange(rating_index) %>% 
  ggplot(aes(reorder(rating_categories, rating_index), rating_count)) +
    geom_col(width = 0.5, fill="lightblue") +
    xlab("Standard & Poors Rating Categpry") +
    ylab("Number of Sovereigns") +
    ylim(0, 15) +
    scale_fill_brewer() +
    theme(axis.text.x = element_text(angle = 45, hjust=1))
```

```{r Display-Number-Of-Ratings-by-Rating-Category-Fitch, fig.cap = "**Number of Sovereigns by Fitch Rating Category**", echo = FALSE}
# Display number of ratings by rating category for Fitch in a figure
fitch_current_ratings <- current_sovereign_ratings$Fitch[!is.na(current_sovereign_ratings$Fitch)]
fitch_current_ratings_table <- table(fitch_current_ratings)
fitch_current_ratings_categories <- names(fitch_current_ratings_table)
fitch_current_ratings_index <- fitch_rating_order[names(fitch_current_ratings_table)]
fitch_current_ratings_counts <- as.integer(fitch_current_ratings_table)
fitch_current_ratings_tibble <- tibble(rating_categories = fitch_current_ratings_categories, 
                                       rating_index = fitch_current_ratings_index, 
                                       rating_count = fitch_current_ratings_counts) %>% 
                                    arrange(rating_index)
fitch_current_ratings_tibble %>% 
  arrange(rating_index) %>% 
  ggplot(aes(reorder(rating_categories, rating_index), rating_count)) +
    geom_col(width = 0.5, fill="lightblue") +
    xlab("Fitch Rating Categpry") +
    ylab("Number of Sovereigns") +
    ylim(0, 15) +
    scale_fill_brewer() +
    theme(axis.text.x = element_text(angle = 45, hjust=1))
```

These figures show that there are about a dozen sovereigns that the rating agencies have assigned their highest rating category, e.g. "AAA", while slightly less than half of the sovereigns have credit ratings with credit grades that represent speculative investments, i.e. credit ratings below "BBB-".


### Historical Sovereign Credit Rating Actions

```{r Initialize-Credit-Rating-Actions-Tibble, echo = FALSE}
# An empty credit rating actions history tibble is created to retain the historical credit
# rating actions. This tibble has columns for the country, rating agency, and the rating 
# actions. The rating actions columns cover long-term and short-term credit ratings for 
# foreign currency and local currency credit rating actions, as well as the date and action 
# label for each action (for a total of 8 columns).
credit_rating_actions_tibble <- tibble(
  long_term_foreign_currency_rating_action_dates = character(),
  long_term_foreign_currency_rating_action_values = character(),
  long_term_local_currency_rating_action_dates = character(),
  long_term_local_currency_rating_action_values = character(),
  short_term__term_foreign_currency_rating_action_dates = character(),
  short_term_foreign_currency_rating_action_values = character(),
  short_term_local_currency_rating_action_dates = character(),
  short_term_local_currency_rating_action_values = character())
colnames(credit_rating_actions_tibble) <- c("Country",
                                            "Agency",
                                            "LTFC_Date",
                                            "LTFC_Action",
                                            "LTLC_Date",
                                            "LTLC_Action",
                                            "STFC_Date",
                                            "STFC_Action",
                                            "STLC_Date",
                                            "STLC_Action")

```

```{r Iteration-Over-Countries-Agencies-Ratings, warning = FALSE, echo = FALSE}
# The following code extracts historical credit rating actions for all countries by the 
# three credit rating agencies. The processing steps are as follows:
#   * Create country credit rating web page urls for all countries
#   * Extract country webpage url and download the html code
#   * Find the table nodes for the agencies in the webpage
#   * Find the table body for each rating agency table
#   * Find the table rows for each table body
#   * Convert table row html to a list of rating action values
#   * Update the credit rating actions history tibble with the rating action values
# Create country web page urls for all countries
country_economics_country_rating_urls <- country_relative_urls %>% 
  mutate(country_url = paste(country_economics, relurl, sep = ""))
# Iterate over all country webpage urls
for (i in 1:dim(country_economics_country_rating_urls[1]))  {
# Get the country url and download the html code for the country webpage
  country_url <- country_economics_country_rating_urls$country_url[i]
  country_html <- read_html(country_url)
# Find the rating agency tables in the country ratings webpage
  country_tables <- country_html %>% html_nodes("table")
# Start by iterating over the rating agency tables in the web page for the country
  for (j in 1:3) {
# Extracting ratings for successive rating agencies
    agency_name <- agencies[j]
    agency_table <- country_tables[j] %>% html_nodes("tbody")
# Get table rows for the credit rating agency    
    agency_table_rows <- agency_table %>% html_nodes("tr")
# Extracting ratings for each credit rating agency
    for (k in 1:length(agency_table_rows)) {
# Convert html to character string with "|" in empty columns
      agency_table_row_string <- gsub("<td></td>", "<td>|</td>", as.character(agency_table_rows[k]))
# Extract the rating data from the table row
      agency_table_row_values <- sub("</td>", "", sub("<td>", "", str_extract_all(agency_table_row_string, "<td>.+</td>", simplify = TRUE)))
# Extract the rating actions from the rating data
      long_term_foreign_currency_rating_action_dates <- 
        ifelse(agency_table_row_values[c(TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE)] == "|", " ", 
               agency_table_row_values[c(TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE)])
      long_term_foreign_currency_rating_action_values <- agency_table_row_values[c(FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE)]
      long_term_local_currency_rating_action_dates <- 
        ifelse(agency_table_row_values[c(FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE)] == "|", " ", 
               agency_table_row_values[c(FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE, FALSE)])
      long_term_local_currency_rating_action_values <- agency_table_row_values[c(FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE)]
      short_term__term_foreign_currency_rating_action_dates <- 
        ifelse(agency_table_row_values[c(FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE)] == "|", " ", 
               agency_table_row_values[c(FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE)])
      short_term_foreign_currency_rating_action_values <- agency_table_row_values[c(FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE, FALSE)]
      short_term_local_currency_rating_action_dates <- 
        ifelse(agency_table_row_values[c(FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE)] == "|", " ", 
               agency_table_row_values[c(FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FALSE)])
      short_term_local_currency_rating_action_values <- agency_table_row_values[c(FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE)]
      rating_actions <- tibble(country_name, agency_name, 
                                      long_term_foreign_currency_rating_action_dates, 
                                      long_term_foreign_currency_rating_action_values,
                                      long_term_local_currency_rating_action_dates,
                                      long_term_local_currency_rating_action_values,
                                      short_term__term_foreign_currency_rating_action_dates,
                                      short_term_foreign_currency_rating_action_values,
                                      short_term_local_currency_rating_action_dates,
                                      short_term_local_currency_rating_action_values
                                      )
      colnames(rating_actions) <- c("Country",
                                      "Agency",
                                      "LTFC_Date",
                                      "LTFC_Action",
                                      "LTLC_Date",
                                      "LTLC_Action",
                                      "STFC_Date",
                                      "STFC_Action",
                                      "STLC_Date",
                                      "STLC_Action")

# Append the rating actions to the credit rating actions tibble
      credit_rating_actions_tibble <- rbind(credit_rating_actions_tibble, rating_actions)
    }
  }
}
credit_rating_actions <- credit_rating_actions_tibble
```
```{r Load-Credit-Rating-Actions, warning = FALSE, message = FALSE, echo = FALSE}
credit_rating_actions_url <- "https://raw.githubusercontent.com/georgeaholt/Capstone/main/CreditRatingActions.csv"
credit_rating_actions <- read_csv(credit_rating_actions_url)

```

```{r Select-Long-Term-Credit-Rating-Actions, echo = FALSE}
# Extract only long-term foreign currency actions
LTFC_credit_rating_actions <- credit_rating_actions[,1:4]
```

```{r Extract-Credit-Rating-Actions-Separating-Qualifiers-Droping-NAs, echo = FALSE}
# Extract credit rating actions
LTFC_credit_rating_actions_cleaned <- LTFC_credit_rating_actions %>% 
  filter(!is.na(LTFC_Date) & !is.na(LTFC_Action)) %>% 
  mutate(Rating_Date = LTFC_Date,
         Rating_Category = sub(" \\(", "", str_extract(LTFC_Action, ".* \\(")),
         Qualifier = str_extract(LTFC_Action, "\\(.*\\)")) %>% 
  filter(!is.na(Rating_Category))
```
Each credit rating agency performs reviews of a sovereign's creditworthiness periodically or as events affecting the sovereign dictate with the objective of providing investors with relatively current information about the riskiness of the sovereign's debt instruments. These reviews may result in announcements of credit rating actions, which are statements about what credit rating is appropriate for a sovereign at the time of the announcement. Announcements can indicate that a different rating category is appropriate than the category most recently indicated by the agency, or it may confirm the most recently announced rating category. If an agency has not previously performed a credit review of a sovereign and initiates ratings for a sovereign, the rating action would typically indicate the initial rating category for a sovereign.

Credit rating actions are sometimes accompanied by a qualifier, such as Stable, Negative, Positive, or Under Review, that provide further information about the agency's views on the direction of a sovereign's credit rating. While the qualifiers provide additional information to investors, they do not directly affect a sovereign's credit rating at a given point in time, and they do not affect the history of a sovereign's credit ratings over historical time periods. Since the emphasis in this report is on credit rating history, the significance of rating qualifiers is not considered in the analysis that follows, although analysis of qualifier significance may be an appropriate subject for further research.

When these qualifier events are excluded from the credit rating action data, the data used for analysis covers `r  length(unique(LTFC_credit_rating_actions_cleaned$Country))` countries and consists of `r length(LTFC_credit_rating_actions_cleaned$Country)` observations. To better understand the process of taking credit rating actions at the credit rating agencies, it is useful to examine the number of rating actions where a rating is either confirmed or changed each year. The set of credit rating action observations used in this report contains observations from `r min(as.numeric(substr(LTFC_credit_rating_actions_cleaned$Rating_Date, 1, 4)))` through November 2020, excluding rating qualifier only events. The number of sovereign credit rating actions excluding rating qualifier events each year is shown in Figure \@ref(fig:Display-Rating-Actions-Over-Time).

```{r Display-Rating-Actions-Over-Time, fig.cap = "**Credit Rating Actions by Year**", echo = FALSE}
# Display credit rating actions over timr ina figure
LTFC_credit_rating_actions_cleaned %>% 
  mutate(Rating_Year = substr(Rating_Date,1 , 4)) %>% 
  group_by(Agency, Rating_Year) %>% 
  summarize(num_actions = n(), .groups = "keep") %>% 
  ggplot(aes(x = Rating_Year, num_actions, fill = Agency)) +
    geom_bar(stat="identity", position = position_dodge()) +
    xlab("Rating Year") +
    ylab("Number of Sovereign Rating Actions") +
    scale_fill_brewer(palette = "Paired") +
    theme(axis.text.x = element_text(angle=90, hjust=1))
```

This bar chart shows that there were very few credit rating actions by each rating agency prior to the year 2000 and overall less than 100 actions per year between 2000 and 2020, with the exception of 7 different years when Fitch produced between 130 and 820 rating actions. Fitch appears to be much more active than Moody's or Standard & Poors, but this may be because Fitch reconfirms many sovereign ratings each year without changing the rating category. Recently, Moody's has apparently been the most active agency in issuing rating actions in the past few years.

### Historical Sovereign Credit Ratings

The information provided by the credit rating actions of each rating agency for each sovereign provides a means of constructing a history of the credit rating for each sovereign by each rating agency over historical time periods. As noted above, most of the credit rating actions for sovereigns have occurred over the dozen or so years prior to 2020. This information is sufficient to provide a time series of credit rating categories assigned by each rating agency for each sovereign for an interval of about 20 years, and it allows some insight into the dynamics of sovereign creditworthiness over this interval.

The process for constructing the annual credit rating time series for each sovereign and rating agency uses the average credit rating for each year where one or more credit rating actions occurred. When there is only one credit rating action by an agency for a sovereign during a given year, the average credit rating is the same as the credit rating category for the action. For example, if Moody's assigns a credit rating category of "A1" to Spain once during a given year, this credit rating action results in the average credit rating of "A1" for the Moody's credit rating for the year. When there are two or more rating actions by an agency for a sovereign during a given year, the average credit rating is the credit rating category obtained by calculating the average ranking of credit categories, rounding the resulting average to the nearest integer ranking, and using the rounded average ranking to obtain the corresponding rating category for the agency. For example, if Moody's assigns a credit rating category of "A1" to Spain on one day during a year and a rating category of "Aa2" on another day during the same year, these credit rating actions result in the average credit rating of "Aa3" as the Moody's credit rating for the year. (This result is obtained by averaging the ranking of 5 for the "A1" rating and the ranking of 3 for the "Aa2" rating, resulting in an average ranking of 4, corresponding to a "Aa3" rating.)

The rating agencies do not take credit rating actions for each sovereign during every year, so the averaging process outlined above does not necessarily result in an annual credit rating of a sovereign by a rating agency for every year during a given time interval. For years where no credit rating actions for a sovereign occurs, the appropriate credit rating category for the year is the credit rating category for the sovereign assigned by the rating agency by its the most recent credit rating action. For example, if Moodys did not issue a credit rating action for Spain during 2019, but Moodys most recent credit rating action for Spain occurred on April 18, 2018, the credit rating category for that action ("Baa1") is the appropriate credit rating category for 2019.



```{r Define-Rating-Ranking-Function, echo = FALSE}
# Define rating ranking for Moodys
credit_rating_descriptions_moodys <- credit_rating_descriptions$Moodys[credit_rating_descriptions$Moodys != ""]
moodys_rating_ranking <- 1:length(credit_rating_descriptions_moodys)
names(moodys_rating_ranking) <- credit_rating_descriptions_moodys
# Define rating ranking for SandP
credit_rating_descriptions_sandp <- credit_rating_descriptions$SandP[credit_rating_descriptions$SandP != ""]
sandp_rating_ranking <- 1:length(credit_rating_descriptions_sandp)
names(sandp_rating_ranking) <- credit_rating_descriptions_sandp
# Define rating ranking for Fitch
credit_rating_descriptions_fitch <- credit_rating_descriptions$Fitch[credit_rating_descriptions$Fitch != ""]
fitch_rating_ranking <- 1:length(credit_rating_descriptions_fitch)
names(fitch_rating_ranking) <- credit_rating_descriptions_fitch
```
```{r Define-Credit-Rating-Ranking-Function, echo = FALSE}
get_rating_ranking <- function(agency_name, rating_category) {
  if (agency_name == "Moodys") {
    return(moodys_rating_ranking[rating_category])
  } else if (agency_name == "SandP") {
    return(sandp_rating_ranking[rating_category])
  } else if (agency_name == "Fitch") {
    return(fitch_rating_ranking[rating_category])
  } 
}
```
```{r Define-Get-Credit-Rating-Category, echo = FALSE}
# Define function to get rating category for rating ranking
get_rating_category <- function(agency_name, rating_ranking) {
  if (agency_name == "Moodys") {
    return(names(moodys_rating_ranking)[rating_ranking])
  } else if (agency_name == "SandP") {
    return(names(sandp_rating_ranking)[rating_ranking])
  } else if (agency_name == "Fitch") {
    return(names(fitch_rating_ranking)[rating_ranking])
  } 
}
```

```{r Iteratively-Generate-Historical-Credit-Ratings, warning = FALSE, message = FALSE, echo = FALSE, tidy = TRUE}
# Set up historical credit ratings tibble
historical_credit_ratings <- tibble(country_name = character(),
                                    agency_name = character(),
                                    year = character(),
                                    rating = character())
# Set initial and final years for credit ratings
initial_rating_year <- 1999
final_rating_year <- 2020
# Get the list of all rated sovereigns
countries <- unique(LTFC_credit_rating_actions_cleaned$Country)
# Iterate over the countries
for (country_name in countries) {
  # Iterate over the rating agencies
  for (agency_name in agencies) {
    # Set up the annual credit ratings by year vector
    credit_rating_by_year <- initial_rating_year:final_rating_year * NA
    names(credit_rating_by_year) <- initial_rating_year:final_rating_year
    # Set up the year-ending credit ratings by year vector
    year_ending_credit_rating_by_year <- initial_rating_year:final_rating_year * NA
    names(year_ending_credit_rating_by_year) <- initial_rating_year:final_rating_year
    # Set up the year-starting credit ratings by year vector
    year_starting_credit_rating_by_year <- initial_rating_year:final_rating_year * NA
    names(year_starting_credit_rating_by_year) <- initial_rating_year:final_rating_year
    # Get the long-term credit rating actions for a country and rating agency
    actions_country <- LTFC_credit_rating_actions_cleaned %>% 
      filter(Country == country_name)
    actions_agency <- actions_country %>% 
      filter(Agency == agency_name)
    actions <- actions_agency %>% 
      dplyr::select(-c(LTFC_Date, LTFC_Action, Qualifier))
    # Check weather there are credit rating actions for the country and rating agency
    # If not, there will be no annual credit ratings for the country and rating agency
    if (nrow(actions) > 0) {
      # get the average, first, and last credit rating action ranks for each year
      credit_rating_actions_ranking <- actions %>% 
        mutate(action_year = substr(Rating_Date, 1, 4),
               Rating_Ranking = get_rating_ranking(agency_name, Rating_Category)) %>% 
        filter(action_year >= 1994) %>% 
        group_by(action_year) %>% 
        summarize(first_rating_action_rank = min(Rating_Ranking),
                  last_rating_action_rank = max(Rating_Ranking),
                  average_rating_action_rank = round(mean(Rating_Ranking), digits = 0))
      # Get rating categories corresponding to average rating action rankings as annual credit ratings
      annual_credit_ratings <- credit_rating_actions_ranking %>% 
        mutate(annual_rating = get_rating_category(agency_name, average_rating_action_rank))
      # Get rating categories corresponding to last rating action rankings as year-end credit ratings
      year_ending_credit_ratings <- credit_rating_actions_ranking %>% 
        mutate(year_ending_rating = get_rating_category(agency_name, last_rating_action_rank))
      # Get rating categories corresponding to first rating action rankings as year-starting credit ratings
      year_starting_credit_ratings <- credit_rating_actions_ranking %>% 
        mutate(year_starting_rating = get_rating_category(agency_name, first_rating_action_rank))
      # Iterate over the annual credit ratings to produce credit ratings per year
      for (k in 1:length(annual_credit_ratings$action_year)) {
        year <- annual_credit_ratings$action_year[k]
        credit_rating_by_year[year] <- annual_credit_ratings$annual_rating[k]
      }
      # Iterate over the year-end credit ratings to produce year-end ratings per year
      for (k in 1:length(year_ending_credit_ratings$action_year)) {
        year <- year_ending_credit_ratings$action_year[k]
        year_ending_credit_rating_by_year[year] <- year_ending_credit_ratings$year_ending_rating[k]
      }
      # Iterate over the year-starting credit ratings to produce year-starting ratings per year
      for (k in 1:length(year_starting_credit_ratings$action_year)) {
        year <- year_starting_credit_ratings$action_year[k]
        year_starting_credit_rating_by_year[year] <- year_starting_credit_ratings$year_starting_rating[k]
      }
      
    # Find the index of the first rating in the ratings by year list
      first_rating_index <- min(which(!is.na(credit_rating_by_year) == TRUE))
      # Set the ratings for the previous years to the year starting rating category for the first rating index
      for (m in 1:first_rating_index - 1) {
        credit_rating_by_year[m] <- year_starting_credit_rating_by_year[first_rating_index]
      }
      # Iterate through years subsequent to the first rating year
      # Set the ratings for the following years where no rating actions were issued
      for (m in (first_rating_index + 1):length(credit_rating_by_year)) {
        # Check for no rating value for each subsequent year and 
        if (is.na(credit_rating_by_year[m])) {
          # If no rating, assign year-ending credit rating for previous year
          credit_rating_by_year[m] <- year_ending_credit_rating_by_year[m - 1]
          year_ending_credit_rating_by_year[m] <- year_ending_credit_rating_by_year[m - 1]
        }
      }
      # Create a credit ratings tibble for the country and rating agency
      credit_ratings_tibble <- tibble(country = country_name, 
                                      agency = agency_name, 
                                      year = names(credit_rating_by_year), 
                                      rating = as.vector(credit_rating_by_year))
      historical_credit_ratings <- rbind(historical_credit_ratings, credit_ratings_tibble)
    }
  }
}
```

## Sovereign Economic and Financial Indicators

As discussed earlier, Cantor and Packer identified several economic and financial indicator variables that are important factors in determining the creditworthiness of sovereign debt issuers. Cantor and Packer also indicated the sources of the data they used in their study, with the World Bank being the primary source at the time of their research. Today, the World Bank remains the most important source of this data, so it is the primary source for the economic and financial data used in this report. Some data is also obtained from the International Monetary Fund (IMF). The following discussion considers each of the economic and financial indicators identified by Cantor and Packer and briefly explores the data available for these indicators.

All of the data obtained from the World Bank is retained in databases maintained by the bank. While the content of these databases is directly available through a web-page based interface, and the data from these databases can be downloaded using a web-based API, it appeared more convenient to separately download the data as *.csv* files and retain these files in a GitHub repository. These files can be downloaded from GitHib subsequently using the *read_csv()* function provided in the R language, which results in a data frame containing the data that can be easily used for further exploration and analysis. The IMF databases are also directly available through a web-page interface, but in this case downloading *.csv * files was the most convenient approach to obtaining the data.

```{r Create-Sovereigns-With-Historical-Ratings-List, echo = FALSE}
# Create sovereigns with historical ratings list
sovereigns_with_historical_ratings <- unique(historical_credit_ratings["country"])
sovereigns_with_historical_ratings_list <- sovereigns_with_historical_ratings %>% 
  left_join(iso_country_codes, by = "country") %>% 
  filter(!is.na(iso2_code))
```
```{r Create-List-of-Selected-Sovereigns, echo = FALSE}
# Define selected sovereigns
selected_sovereigns <- c("Brazil", "China", "India", "Italy", "Malaysia", "Mexico", "Spain", "South Africa", "Turkey", "United States")
```

To illustrate the comparative historical behavior of the economic and financial indicators across sovereigns, time series charts of each indicator for multiple sovereigns are included in the following discussion. However, since `r  length(sovereigns_with_historical_ratings_list$country)` sovereigns are included in the overall analysis, time series charts for only a limited set of sovereigns are presented as illustrations.

### GNI Per Capita
 
Cantor and Parker identified per capita income as an important factor in determining sovereign credit ratings. In this report, the per capita value for gross national income (GNI. Formerly GNP) expressed in current international dollars and converted by a purchasing power parity (PPP) conversion factor is used as the indicator for per capita income. GNI is the sum of value added by all resident producers plus any product taxes (less subsidies) not included in the valuation of output plus net receipts of primary income (compensation of employees and property income) from abroad. The PPP conversion factor is a spatial price deflator and currency converter that eliminates the effects of the differences in price levels between countries. The data for GNI per capita for each sovereign is downloaded from a World Bank database.

The time series for GNI per capita are presented in Figure \@ref(fig:Get-GNI-Per-Capita-Data). This indicator appears to exhibit roughly linear growth over time.

```{r Get-GNI-Per-Capita-Data, fig.cap = "**GNI Per Capita by Year**", message = FALSE, warning = FALSE, echo = FALSE}
gni_per_capita_url <- "https://raw.githubusercontent.com/georgeaholt/Capstone/main/GNI%20Per%20Capita.csv"
gni_per_capita_temp <- read_csv(gni_per_capita_url)
gni_per_capita <- gni_per_capita_temp %>% 
  dplyr::select(-c("Series Name", "Series Code")) %>% 
  pivot_longer(!c("Country Name", "Country Code"), names_to = "yearval", values_to = "per_capita_gni_str") %>% 
  filter(!(per_capita_gni_str == "..")) %>% 
  mutate(year = as.numeric(substr(yearval, 1, 4)),
         GNI_per_capita = as.numeric(per_capita_gni_str)) %>% 
  dplyr::select(-c(yearval, per_capita_gni_str))
colnames(gni_per_capita) <- c("country", "country_code", "year", "per_capita_gni")
gni_per_capita %>% 
  filter(country %in% selected_sovereigns) %>% 
  ggplot(aes(year, per_capita_gni, color = country)) + 
    geom_line(lwd = 1) +
    xlab("Year") +
    ylab("GNI Per Capita") +
    scale_colour_brewer("Sovereigns", palette="Paired")
```

### GNI Growth

The second variable determining credit ratings identified by Cantor and Packer is sovereign GDP growth per year. GDP growth is now called GNI growth. In this report, the measure of sovereign economy's GDP growth is measured by the change in the volume of its output or in the real incomes of its residents at market prices based on constant local currency. Aggregates are based on constant 2010 U.S. dollars. GNI is the sum of gross value added by all resident producers in the economy plus any product taxes and minus any subsidies not included in the value of the products. It is calculated without making deductions for depreciation of fabricated assets or for depletion and degradation of natural resources. GDP accounts for all domestic production, regardless of whether the income accrues to domestic or foreign institutions. The data for GNI growth for each sovereign is downloaded from a World Bank database.

The time series for GNI growth are shown in Figure \@ref(fig:Get-GNI-Growth-Data). This indicator appears to fluctuate substantially over the 20-year interval covered by the chart, with growth rates as high as 14 percent and as low as -6 percent. All of the selected set of sovereigns were impacted by events in 2009, although China was less affected than the other sovereigns shown.

```{r Get-GNI-Growth-Data, fig.cap = "**GNI Growth by Year**", message = FALSE, warning = FALSE, echo = FALSE}
# Get GNI growth data and display it in a figure
gni_growth_url <- "https://raw.githubusercontent.com/georgeaholt/Capstone/main/GNI%20Growth.csv"
gni_growth_temp <- read_csv(gni_growth_url)
gni_growth <- gni_growth_temp %>% 
  dplyr::select(-c("Series Name", "Series Code")) %>% 
  pivot_longer(!c("Country Name", "Country Code"), names_to = "yearval", values_to = "growth_gni_str") %>% 
  filter(!(growth_gni_str == "..")) %>% 
  mutate(year = as.numeric(substr(yearval, 1, 4)),
         GNI_growth = as.numeric(growth_gni_str)) %>% 
  dplyr::select(-c(yearval, growth_gni_str))
colnames(gni_growth) <- c("country", "country_code", "year", "growth_gni")
gni_growth %>% 
  filter(country %in% selected_sovereigns) %>% 
  ggplot(aes(year, growth_gni, color = country)) + 
    geom_line(lwd = 1) +
    xlab("Year") +
    ylab("GNI Growth Rate (%)") +
    scale_colour_brewer("Sovereigns", palette="Paired")

```

### CPI Inflation

Cantor and Packer identified consumer price index (CPI) inflation as a third determinant of sovereign credit ratings. In this report, inflation as measured by the consumer price index reflects the annual percentage change in the cost to the average consumer of acquiring a basket of goods and services that may be fixed or changed at specified intervals, such as yearly. The Laspeyres formula is generally used. (The Laspeyres Index is calculated by working out the cost of a group of commodities at current prices, dividing this by the cost of the same group of commodities at base period prices, and then multiplying by 100. The data for CPI inflation for each sovereign is downloaded from a World Bank database.

The time series for CPI inflation rate are shown in Figure \@ref(fig:Get-CPI-Inflation-Data). Most of the selected sovereigns have inflation rates under 5 percent over the 20-year interval covered by the chart, but Turkey had extreme inflation early in this period and more recently had higher than typical inflation.

```{r Get-CPI-Inflation-Data, fig.cap = "**CPI Inflation Rate by Year**", message = FALSE, warning = FALSE, echo = FALSE}
# Get CPI inflation data and display it ina figure
infllation_cpi_url <- "https://raw.githubusercontent.com/georgeaholt/Capstone/main/CPI%20Inflation.csv"
inflation_cpi_temp <- read_csv(infllation_cpi_url)
inflation_cpi <- inflation_cpi_temp %>% 
  dplyr::select(-c("Series Name", "Series Code")) %>% 
  pivot_longer(!c("Country Name", "Country Code"), names_to = "yearval", values_to = "inflation_cpi_str") %>% 
  filter(!(inflation_cpi_str == "..")) %>% 
  mutate(year = as.numeric(substr(yearval, 1, 4)),
         CPI_inflation = as.numeric(inflation_cpi_str)) %>% 
  dplyr::select(-c(yearval, inflation_cpi_str))
colnames(inflation_cpi) <- c("country", "country_code", "year", "cpi_inflation")
inflation_cpi %>% 
  filter(country %in% selected_sovereigns) %>% 
  ggplot(aes(year, cpi_inflation, color = country)) + 
    geom_line(lwd = 1) +
    xlab("Year") +
    ylab("CPI Inflation Rate (%)") +
    scale_colour_brewer("Sovereigns", palette="Paired")

```

### Fiscal Balance

The fourth determinant of sovereign credit ratings identified by Cantor and Packer is a sovereign's fiscal balance. Fiscal balance is defined as the average annual central government budget surplus relative to GDP. After investigating potential sources for this data, including the World Bank and the International Monetary Fund, sufficient data to perform the analyses in this report did not appear to be available. The U.S. Central Intelligence Agency (CIA) does occasionally publish fiscal balance information for many countries, but this informaion is typically only available for select years. Cantor and Packer indicated that there were data limitations that affected their use of this indicator. These data limitations may be more important today than in the 1990s, since there are many more sovereigns with ratings today. The linear regression analysis performed by Cantor and Packer also indicated that fiscal balance was relatively unimportant as an indicator for predicting sovereign credit ratings. Because of these limitations, fiscal balance is not included in the analysis in this report, and its usefulness in predicting sovereign credit ratings will be subject to further research.


### Current Account Balance

Cantor and Packer identified a sovereign's external balance as a fifth determinant of sovereign credit ratings. They define external balance as a sovereign's average annual current account surplus relative to GDP. In this report, current account balance as a percent of GNI is used as the corresponding indicator of a sovereign's external balance. Current account balance is defined as the sum of net exports of goods and services, net primary income, and net secondary income. This indicator is often referred to as the balance of payments for a sovereign. The data for the current account balance as a percent of GDP for each sovereign is downloaded from a World Bank database.

The time series for current account balance are presented in Figure \@ref(fig:Get-Current-Account-Balance-Data). The chart shows that until about 2013, the selected sovereigns had diverging current account balances as a percent of their GDP, with Malaysia having the largest surplus and Spain and Turkey having the largest deficits. Since 2013, the selected sovereigns appear to have current account balances that are less in absolute value than 5 percent.

```{r Get-Current-Account-Balance-Data, fig.cap = "**Current Account Balance by Year**", message = FALSE, warning = FALSE, echo = FALSE}
# Get current account data and display it in a figure
current_account_balance_url <- "https://raw.githubusercontent.com/georgeaholt/Capstone/main/Current%20Account%20Balance.csv"
current_account_balance_temp <- read_csv(current_account_balance_url)
current_account_balance <- current_account_balance_temp %>% 
  dplyr::select(-c("Series Name", "Series Code")) %>% 
  pivot_longer(!c("Country Name", "Country Code"), names_to = "yearval", values_to = "current_account_balance_str") %>% 
  filter(!(current_account_balance_str == "..")) %>% 
  mutate(year = as.numeric(substr(yearval, 1, 4)),
         balance_current_account = as.numeric(current_account_balance_str)) %>% 
  dplyr::select(-c(yearval, current_account_balance_str))
colnames(current_account_balance) <- c("country", "country_code", "year", "current_account_ratio")
current_account_balance %>% 
  filter(country %in% selected_sovereigns) %>% 
  ggplot(aes(year, current_account_ratio, color = country)) + 
    geom_line(lwd = 1) +
    xlab("Year") +
    ylab("Current Account Balance (% of GNI)") +
    scale_colour_brewer("Sovereigns", palette="Paired")

```

### External Debt

External debt was identified as a sixth determinant of sovereign credit ratings by Cantor and Packer. They define external debt as foreign currency debt as a percentage of exports. External debt is that part of the total debt in a country that is owed to creditors outside the country. The debtors can be the government, corporations or private households. The debt includes money owed to private commercial banks, other governments, or international financial institutions.

External indebtedness affects a sovereign's creditworthiness and investor perceptions. Non-reporting sovereigns might have outstanding debt with the World Bank, other international financial institutions, or private creditors. Total debt service is contrasted with sovereigns' ability to obtain foreign exchange through exports of goods, services, primary income, and workers' remittances. Debt ratios are used to assess the sustainability of a sovereign's debt service obligations, but no absolute rules determine what values are too high. Empirical analysis of developing countries' experience and debt service performance shows that debt service difficulties become increasingly likely when the present value of debt reaches 200 percent of exports. Still, what constitutes a sustainable debt burden varies by sovereign. Sovereigns with fast-growing economies and exports are likely to be able to sustain higher debt levels.

Information on total external debt is not readily available for many sovereigns, so central government debt as a percentage of GNI is used as an alternative measure of sovereign indebtedness in this report. Data for central government debt is available from the IMF for some sovereigns. This data was downloaded in the form of a *.csv* file from the IMF web site and retained in a *github* repository, and this data is extracted from the *.csv* file in the repository using the *read.csv()* function.

```{r Get-External-Debt-Data, fig.cap = "**External Debt Ratio by Year**", message = FALSE, warning = FALSE, echo = FALSE}
# Get external debt data and display it in a figure
external_debt_url <- "https://raw.githubusercontent.com/georgeaholt/Capstone/main/External%20Debt.csv"
external_debt_temp <- read_csv(external_debt_url)
external_debt_temp <- external_debt_temp %>% 
  rename(Country_Name = "Country Name", Country_Code = "Country Code")
external_debt <- external_debt_temp %>% 
  dplyr::select(-c("Series Name", "Series Code")) %>% 
  pivot_longer(!c(Country_Name, Country_Code), names_to = "yearval", values_to = "external_debt_str") %>% 
  filter(!(external_debt_str == "..")) %>% 
  mutate(year = as.numeric(substr(yearval, 2, 5)),
         debt_external = as.numeric(external_debt_str)) %>% 
  dplyr::select(-c(yearval, external_debt_str))
colnames(external_debt) <- c("country", "country_code", "year", "external_debt_ratio")
external_debt %>% 
  filter(country %in% selected_sovereigns) %>% 
  ggplot(aes(year, external_debt_ratio, color = country)) + 
    geom_line(lwd = 1) +
    xlab("Year") +
    ylab("Central Government Debt (% of GNI)") +
    scale_colour_brewer("Sovereigns", palette="Paired")

```

The chart in Figure \@ref(fig:Get-External-Debt-Data) shows *external_debt_ratio* for some of the selected sovereigns. This chart shows that the ratio has been increasing in recent years.

Unfortunately, this dataset does not include information for many of the most highly rated-sovereigns, e.g., the United States. So its inclusion in subsequent analyses produces indicator observations that do not contain observations for these highly-rated sovereigns, which means that any models trained using indicator observations that include the *external_debt_ratio* will produce biased results that do not cover higher credit rating categories. Consequently, development of sovereign credit rating prediction models in the remainder of this report will not include *external_debt_ratio* as an indicator variabe.

### Developing Economy Indicator

```{r Download-Developing-Country-List, echo = FALSE}
developing_countries_url <- "https://raw.githubusercontent.com/georgeaholt/Capstone/main/DevelopingCountries.csv"
developing_countries <- read.csv(developing_countries_url)
developing_country_list <- unlist(developing_countries$Country)
```
Cantor and Packer included an indicator for economic development as a determinant of sovereign credit ratings. According to the IMF, developing countries are those countries whose standard of living, income, economic and industrial development remain more or less below average. In this report, a list of `r dim(developing_countries)[1]` sovereigns provided by the IMF is used to identify the sovereigns with credit ratings that are considered to be developing countries. This data is contained in a *.csv* file retained in a *github* repository, and it is extracted from the repository using the *read_csv* function.

### Sovereign Indicators

The indicators discussed above provide the economic and financial metrics required to develop, calibrate, and test credit rating prediction models. These indicators are assembled into a set of observations for each sovereign and year considered in the modeling process. A small number of sovereigns do not have sufficient data to support the modeling process, so these sovereigns are dropped from consideration. The modeling process also requires that the indicators for each sovereign, year, and indicator have values, i.e., are not NAs, so the indicators for each sovereign and year with missing values are also dropped from the analysis.

```{r Create-Indicators-Tibble, warnings = FALSE, message = FALSE, echo = FALSE}
# Get raw indicators by joining the individual indicator tibbles
indicators_joined <- left_join(left_join(left_join(gni_per_capita, 
                      gni_growth), inflation_cpi), current_account_balance)
# Drop rows that have NAs
indicators_filtered <- indicators_joined %>% 
  filter(!is.na(per_capita_gni) & !is.na(growth_gni) & !is.na(cpi_inflation) & 
          !is.na(current_account_ratio))

indicators <- indicators_filtered %>% 
  mutate(developing = ifelse(country %in% developing_country_list, 1, 0))
```
## Sovereign Credit Rating Prediction

Credit rating prediction is an ordinal classification process from a data science viewpoint. Credit ratings for each rating agency are an ordered collection of rating categories, and the ordering of the rating categories for each agency provides additional ranking information that supplements the assignment of a particular rating category. From a theoretical viewpoint, sovereign credit rating prediction should account for ordinal classification across a set of discrete credit rating categories and for the information provided by the ranking of the credit rating categories. 

Cantor and Packer and other earlier analysts of sovereign credit ratings used a linear regression approach to describe the relationship between credit rating categories and explanatory variables. The linear regression approach assigns a numerical value to each credit rating category that provides a ranking of the rating categories that effectively assumes that the distance between successive rating categories in the ranking is the same for all rating categories. There is nothing inherent in the rating agencies methodologies that supports this assumption, so the distances between successive ratings are effectively unknown. Thus the linear regression approach makes assumptions about rating categories and the distances between successive ratings that is not consistent with the ordinal classification assumptions.

This report offers an alternative perspective on predicting sovereign credit ratings using modeling approaches that are consistent with the ordinal classification process outlined above. In particular, two different modeling approaches based on machine learning models are developed and applied to the sovereign credit rating and indicator observations discussed in the previous sections of this report. These approaches are:

  * Ordinal Forest Models
  * Linear Discriminant Analysis Models

An important issue in developing sovereign credit rating prediction models is the relatively small number of credit rating observations for an individual rating agency each year. At best the number of observations is limited by the number of sovereigns rated by each agency, which is currently slightly over 120 sovereigns for each of the rating agencies, but has been less in previous years. Using a single years observations provides an insufficient basis for training (calibrating) a sovereign credit rating model, because all of the credit rating categories in a rating agency's rating hierarchy typically do not appear in a single year, and because the lack of one or more credit rating categories for an agency in a given year makes it impossible to incorporate the unobserved ratings in the predictive model.

To address this issue, this report uses all of the years for which credit rating and indicator observations are available as the basis for developing credit rating prediction models. Under this assumption, every year covered is treated the same as all other years in the overall observation set. This assumption leads to an observation set with more than 2,000 observations for each rating agency that includes observations of all of the credit rating categories in each of the rating agencies rating hierarchies, which appears sufficient to train the desired credit rating models. At the same time, this assumption effectively assumes that the importance of the indicator variables in predicting an agency's credit ratings does not change over time. Some research (see [@reusens]) has indicated that the rating agencies may change their weighting of some indicator variables over an extended period of time, so this assumption deserves some additional analysis, which will be deferred for future research.

Natural logarithms of the values of *cpi_inflation* are used as observations, consistent with the analysis of Cantor and Packer.

### Relationship Between Ratings and Indicators

In this section, the relationships between each rating agency's credit rating categories and the economic and financial indicators are explored. This is accomplished by plotting the distribution of the values of each indicator for each credit rating category separately for each rating agency. The distributions are presented as horizontal boxplots.
```{r Generate-Moodys-Observations, warnings = FALSE, echo = FALSE}
# Generate Moodys observations
moodys_historical_ratings <- historical_credit_ratings %>% 
  filter(agency == "Moodys") %>% 
  mutate(rating = factor(rating, ordered = TRUE, levels = names(moodys_rating_order)),
         year = as.integer(year))
moodys_observations <- merge(moodys_historical_ratings, indicators, by = c("country", "year")) %>% 
  mutate(per_capita_gni = log(per_capita_gni)) %>% 
  dplyr::select(-c(agency, country_code))
```
```{r Generate-SandP-Observations, warning = FALSE, echo = FALSE}
# Generate S and P observations
sandp_historical_ratings <- historical_credit_ratings %>% 
  filter(agency == "SandP") %>% 
  mutate(rating = factor(rating, ordered = TRUE, levels = names(sandp_rating_order)),
         year = as.integer(year))
sandp_observations <- merge(sandp_historical_ratings, indicators, by = c("country", "year")) %>% 
  mutate(per_capita_gni = log(per_capita_gni)) %>% 
  dplyr::select(-c(agency, country_code))
```
```{r Generate-Fitch-Observations, warning = FALSE, echo = FALSE}
# Generate Fitch observations
fitch_historical_ratings <- historical_credit_ratings %>% 
  filter(agency == "Fitch") %>% 
  mutate(rating = factor(rating, ordered = TRUE, levels = names(fitch_rating_order)),
         year = as.integer(year))
fitch_observations <- merge(fitch_historical_ratings, indicators, by = c("country", "year")) %>% 
  mutate(per_capita_gni = log(per_capita_gni)) %>% 
  dplyr::select(-c(agency, country_code))
```


```{r Display-Ratings-vs-Per-Capita-GNI, fig.cap = "**Per Capita GNI vs Agency Rating Category**", echo = FALSE}
# Plot ratings vs per capita GNI for 3 agencies
per_capita_gni_plot_moodys <- 
  moodys_observations %>% 
  ggplot(aes(per_capita_gni, rating, fill = "lightblue")) +
    geom_boxplot(fill = "lightblue") +
    xlab("ln Per Capita GNI") +
    ylab("Moody's Rating")
per_capita_gni_plot_sandp <- 
  sandp_observations %>% 
  ggplot(aes(per_capita_gni, rating, fill = "lightblue")) +
    geom_boxplot(fill = "lightblue") +
    xlab("ln Per Capita GNI") +
    ylab("S & P Rating")
per_capita_gni_plot_fitch <- 
  fitch_observations %>% 
  ggplot(aes(per_capita_gni, rating, fill = "lightblue")) +
    geom_boxplot(fill = "lightblue") +
    xlab("ln Per Capita GNI") +
    ylab("Fitch Rating")
  
plot_grid(per_capita_gni_plot_moodys, per_capita_gni_plot_sandp, per_capita_gni_plot_fitch, align = "h", nrow = 1)
```


The relationships between each rating agency's credit rating categories and *per_capita_gni* is presented in Figure \@ref(fig:Display-Ratings-vs-Per-Capita-GNI). These plots appear to show a positive exponential relationship between higher ratings and *per_capita_gni*.



```{r Display-Ratings-vs-GNI-Growth, fig.cap = "**GNI Growth Rate vs Agency Rating Category**", echo = FALSE}
# Plot ratings vs GNI growth for 3 agencies
gni_growth_plot_moodys <- 
  moodys_observations %>% 
  ggplot(aes(growth_gni, rating, fill = "lightblue")) +
    geom_boxplot(fill = "lightblue") +
    xlab("GNI Growth Rate") +
    ylab("Moody's Rating")
gni_growth_plot_sandp <- 
  sandp_observations %>% 
  ggplot(aes(growth_gni, rating, fill = "lightblue")) +
    geom_boxplot(fill = "lightblue") +
    xlab("GNI Growth Rate") +
    ylab("S & P Rating")
gni_growth_plot_fitch <- 
  fitch_observations %>% 
  ggplot(aes(growth_gni, rating, fill = "lightblue")) +
    geom_boxplot(fill = "lightblue") +
    xlab("GNI Growth Rate") +
    ylab("Fitch Rating")
  
plot_grid(gni_growth_plot_moodys, gni_growth_plot_sandp, gni_growth_plot_fitch, align = "h", nrow = 1)
```


The relationships between each rating agency's credit rating categories and *gni_growth* is presented in Figure \@ref(fig:Display-Ratings-vs-GNI-Growth). *gni_growth* appears to have a modest negative impact on credit ratings.


```{r Display-Ratings-vs-CPI-Inflation, fig.cap = "**CPI Inflation Rate vs Agency Rating Category**", echo = FALSE}
# Plot ratings vs CPI inflation for 3 agencies
cpi_inflation_plot_moodys <- 
  moodys_observations %>% 
  ggplot(aes(cpi_inflation, rating, fill = "lightblue")) +
    geom_boxplot(fill = "lightblue") +
    xlab("CPI Inflation Rate") +
    ylab("Moody's Rating")
cpi_inflation_plot_sandp <- 
  sandp_observations %>% 
  ggplot(aes(cpi_inflation, rating, fill = "lightblue")) +
    geom_boxplot(fill = "lightblue") +
    xlab("CPI Inflation Rate") +
    ylab("S & P Rating")
cpi_inflation_plot_fitch <- 
  fitch_observations %>% 
  ggplot(aes(cpi_inflation, rating, fill = "lightblue")) +
    geom_boxplot(fill = "lightblue") +
    xlab("CPI Inflation Rate") +
    ylab("Fitch Rating")
  
plot_grid(cpi_inflation_plot_moodys, cpi_inflation_plot_sandp, cpi_inflation_plot_fitch, align = "h", nrow = 1)
```


The relationships between each rating agency's credit rating categories and *cpi_inflation* is presented in Figure \@ref(fig:Display-Ratings-vs-CPI-Inflation). *cpi_inflation* appears to have a modest negative impact on credit ratings.

 
```{r Display-Ratings-vs-Current-Account-Ratio, fig.cap = "**Current Account Ratio vs Agency Rating Category**", echo = FALSE}
# Plot ratings vs current account ratio for 3 agencies
current_account_ratio_plot_moodys <- 
  moodys_observations %>% 
  ggplot(aes(current_account_ratio, rating, fill = "lightblue")) +
    geom_boxplot(fill = "lightblue") +
    xlab("Current Account Ratio") +
    ylab("Moody's Rating")
current_account_ratio_plot_sandp <- 
  sandp_observations %>% 
  ggplot(aes(current_account_ratio, rating, fill = "lightblue")) +
    geom_boxplot(fill = "lightblue") +
    xlab("Current Account Ratio") +
    ylab("S & P Rating")
current_account_ratio_plot_fitch <- 
  fitch_observations %>% 
  ggplot(aes(current_account_ratio, rating, fill = "lightblue")) +
    geom_boxplot(fill = "lightblue") +
    xlab("Current Account Ratio") +
    ylab("Fitch Rating")
  
plot_grid(current_account_ratio_plot_moodys, current_account_ratio_plot_sandp, current_account_ratio_plot_fitch, align = "h", nrow = 1)
```


The relationships between each rating agency's credit rating categories and *current_accountt_ratio* is presented in Figure \@ref(fig:Display-Ratings-vs-Current-Account-Ratio). *current_account_ratio* appears to have a modest positive impact on credit ratings.


```{r Display-Developing-vs-Developed, fig.cap = "**Agency Rating Category Developing vs Developed**", echo = FALSE}
# Plot developing and developed distributions for 3 agencies
developing_plot_moodys <- moodys_observations %>% 
  filter(developing == 1) %>% 
  ggplot(aes(rating)) +
    geom_bar() +
    theme(axis.text.x = element_text(angle = 90)) +
    ggtitle("Developing") +
    xlab("Moody's Rating")
developed_plot_moodys <- moodys_observations %>% 
  filter(developing == 0) %>% 
  ggplot(aes(rating)) +
    geom_bar() +
    theme(axis.text.x = element_text(angle = 90)) +
    ggtitle("Developed") +
    xlab("Moody's Rating")
developing_plot_sandp <- sandp_observations %>% 
  filter(developing == 1) %>% 
  ggplot(aes(rating)) +
    geom_bar() +
    theme(axis.text.x = element_text(angle = 90)) +
    ggtitle("Developing") +
    xlab("S & P Rating")
developed_plot_sandp <- sandp_observations %>% 
  filter(developing == 0) %>% 
  ggplot(aes(rating)) +
    geom_bar() +
    theme(axis.text.x = element_text(angle = 90)) +
    ggtitle("Developed") +
    xlab("S & P Rating")
developing_plot_fitch <- fitch_observations %>% 
  filter(developing == 1) %>% 
  ggplot(aes(rating)) +
    geom_bar() +
    theme(axis.text.x = element_text(angle = 90)) +
    ggtitle("Developing") +
    xlab("Fitch Rating")
developed_plot_fitch <- fitch_observations %>% 
  filter(developing == 0) %>% 
  ggplot(aes(rating)) +
    geom_bar() +
    theme(axis.text.x = element_text(angle = 90)) +
    ggtitle("Developed") +
    xlab("Fitch Rating")

plot_grid(developing_plot_moodys, developed_plot_moodys, 
          developing_plot_sandp, developed_plot_sandp,
          developing_plot_fitch, developed_plot_fitch,
          align = "h", nrow = 3, ncol = 2)
```


Figure \@ref(fig:Display-Developing-vs-Developed) shows separate distributions of credit rating categories for developing and developed economies for each rating agency. The distributions indicate that the development status for a sovereign's economy has a significant impact on credit rating assessments.


```{r Randomly-Partition-Moodys-Observations, warning = FALSE, message = FALSE, echo = FALSE}
# Randomly partition Moody's observations into train and test tibbles
set.seed(7, sample.kind="Rounding")
moodys_test_size <- floor(0.3 * nrow(moodys_observations))
test_index <- sample(seq_len(nrow(moodys_observations)), size = moodys_test_size)
moodys_observations_train <- moodys_observations[-test_index,]
moodys_observations_test <- moodys_observations[test_index,]

```
```{r Randomly-Partition-SandP-Observations, warning = FALSE, message = FALSE, echo = FALSE}
# Randomly partition SandP observations into train and test tibbles
set.seed(7, sample.kind="Rounding")
sandp_test_size <- floor(0.3 * nrow(sandp_observations))
test_index <- sample(seq_len(nrow(sandp_observations)), size = sandp_test_size)
sandp_observations_train <- sandp_observations[-test_index,]
sandp_observations_test <- sandp_observations[test_index,]
```
```{r Randomly-Partition-Fitch-Observations, warning = FALSE, message = FALSE, echo = FALSE}
# Randomly partition Fitch observations into train and test tibbles
set.seed(7, sample.kind="Rounding")
fitch_test_size <- floor(0.3 * nrow(fitch_observations))
test_index <- sample(seq_len(nrow(fitch_observations)), size = fitch_test_size)
fitch_observations_train <- fitch_observations[-test_index,]
fitch_observations_test <- fitch_observations[test_index,]
```


### Ordinal Forest Models

Ordinal forest models (see [@hornung]) are a relatively new approach to describing the relationship between an ordinal response variable, such as a credit rating, and a set of explanatory variables. These models are similar to random forest regression models, where a continuous outcome is related to some explanatory variables, but in this case the outcomes are an ordered set of classes, such as credit ratings. A straightforward forest-based prediction method for ordinal response variables consists of simply considering a regression forest using the class values $1,...,J$ of the response variable for the corresponding classes. However, this procedure is suboptimal because the extents of the classes of the ordinal response variable, or “class widths”, differ from class to class.

In the ordinal forest model, the class widths are the widths of $J$ adjacent intervals in the range of an underlying continuous response variable; each of the $J$ intervals correspond to the $J$ classes of the ordinal response variable. The single assumption in this model is that, underlying
the observed ordinal variable $y$, there exists a particular known or unknown refined continuous variable $y^*$ that determines the values of the
ordinal variable. The relationship between this continuous variable $y^*$ and $y$ is such that the higher the value of $y^*$ is for an observation, the higher is the class of the ordinal response variable for that observation, e.e., if $y^*$ falls into the $j$th interval of $J$ adjacent intervals, $y$ will take the value $j$.

The ordinal forest model is designed for the common situation in which the underlying continuous variable is not measured or is unknown. In ordinal forest, interval boundaries in $y^*$ corresponding to the different classes of $y$ are estimated or optimized by maximizing the OOB prediction performance of regression forests. Using score values that correspond to these optimized class intervals instead of using the class values $1,...,J$ leads to an improvement in prediction performance. (The Out-of-bag (OOB) error, also called out-of-bag estimate, is a method of measuring the prediction error of random forests, boosted decision trees, and other machine learning models utilizing bootstrap aggregating (bagging) to sub-sample data samples used for training.)

A separate ordinal forest model is developed for each rating agency using the historical observations of sovereign credit ratings and corresponding economic and financial indicator values. Each model is trained using a randomly-selected subset of the historical observations, and the fitted model is next used to predict sovereign credit ratings using the indicators for a random complement test subset of the observations. The predicted credit ratings are then compared to the test subset credit ratings to assess the accuracy of the predictions.

#### Moody's Ordinal Forest Model

The Moody's ordinal forest model is trained using a subset comprised of `r length(moodys_observations_train$country)` observations. The observations cover ratings for `r length(unique(moodys_observations_train$country))` countries across `r  length(unique(moodys_observations_train$rating))` rating categories. The summary output from training this model is shown below.

```{r Fit-Moodys-Rating-Ordinal-Forest-Model, warning = FALSE, message = FALSE, echo = FALSE}
# Fit Moodys ordinalforest model
moodys_observations_train_data <- moodys_observations_train %>% 
  dplyr::select(-c("country", "year")) 
ordfor_fit_moodys <- ordfor(depvar = "rating", data = moodys_observations_train_data, 
                            nsets=100, ntreeperdiv=100, ntreefinal=500, 
                            perffunction = "probability")
```
```{r Display-Moodys-Ordinal-Forest-Fit, comment = "", size = "scriptsize", warning = FALSE, echo = FALSE}
# Display Moodys ordinal forest object
ordfor_fit_moodys
```

The fitted model assigns a different level of importance to each of the indicator variables, as shown in the following table.
```{r Display-Moodys-Ordinal-Forest-Importance, comment = "", warning = FALSE, echo = FALSE}
# Display Moodys ordinal forest variable importance
ordfor_fit_moodys$varimp
```
The table indicates that *per_capita_gni* is the first most important determinant of Moody's sovereign credit ratings.

The fitted ordinal forest model is next used to predict the Moody's sovereign credit ratings based upon the randomized test set of indicators for each sovereign. The model calculates the probability of each credit rating category for each sovereign and its associated indicator values. The test set for the Moody's model contains `r length(moodys_observations_test$country)` observations covering `r  length(unique(moodys_observations_test$country))` sovereigns across `r length(unique(moodys_observations_train$rating))` rating categories.  The predicted ratings for the test set are compared to the actual test set ratings in the confusion matrix shown in Table \ref{tab:Generate-And-Display-Moodys-Prediction-Counts-Ordinal-Forest}. A visualization of the confusion matrix is presented in Figure \@ref(fig:Plot-Moodys-Ordinal-Forest-Mosaic).

```{r Predict-Moodys-Ordinal-Forest-Ratings, echo = FALSE}
# Predict Moodys ordinal forest ratings
moodys_observations_test_data <- moodys_observations_test %>% 
  dplyr::select(-c(country, year))
moodys_rating_predictions_ordinal_forest <- predict(ordfor_fit_moodys, newdata = moodys_observations_test_data)
```
```{r Generate-And-Display-Moodys-Prediction-Counts-Ordinal-Forest, echo = FALSE}
# Produce Moodys ordinal forest confusion matrix
moodys_observed_ratings_ordinal_forest <- factor(moodys_observations_test_data$rating, 
                                                 levels = moodys_rating_categories, ordered = TRUE)
moodys_predicted_ratings_ordinal_forest <- factor(moodys_rating_predictions_ordinal_forest$ypred, 
                                                  levels = moodys_rating_categories, ordered = TRUE)
moodys_prediction_counts_ordinal_forest <- table(moodys_predicted_ratings_ordinal_forest, 
                                                 moodys_observed_ratings_ordinal_forest)

moodys_ordinal_forest_tibble <- tibble(moodys_predicted_ratings_ordinal_forest, moodys_observed_ratings_ordinal_forest)

knitr::kable(moodys_prediction_counts_ordinal_forest, 
             caption = "Moody's Ordinal Forest Model Confusion Matrix", 
             format = "latex", 
             booktabs = TRUE) %>% 
  kable_styling(latex_options = c("striped", "scale_down")) %>% 
    add_header_above(header = c("Actual Rating " = 1, "Predicted Rating" = dim(moodys_prediction_counts_ordinal_forest)[1] - 1))

```

```{r Plot-Moodys-Ordinal-Forest-Mosaic, fig.cap = "Moody's Ordinal Forest Model Prediction Mosaic", fig.height = 8, fig.width = 8, echo = FALSE}
# Produce Moodys ordinal forest mosaic chart
mosaicplot(moodys_prediction_counts_ordinal_forest,
           main = "Moody's Ordinal Forest Credit Ratings Mosaic Chart",
           color = c("slateblue", "slateblue1"),
           xlab = "Observed Rating", 
           ylab = "Predicted Rating")

```


#### Standard and Poors Ordinal Forest Model

The Standard and Poors ordinal forest model is trained using a subset comprised of `r length(sandp_observations_train$country)` observations. The observations cover ratings for `r length(unique(sandp_observations_train$country))` countries across `r  length(unique(sandp_observations_train$rating))` rating categories. The summary output from training this model is shown below.

```{r Fit-SandP-Rating-Ordinal-Forest-Model, warnings = FALSE, message = FALSE, echo = FALSE}
# Fit S and P ordinalforest model
sandp_observations_train_data <- sandp_observations_train %>% 
  dplyr::select(-c("country", "year"))
ordfor_fit_sandp <- ordfor(depvar = "rating", data = sandp_observations_train_data, 
                            nsets=100, ntreeperdiv=100, ntreefinal=500, 
                            perffunction = "probability")
```
```{r Display-SandP-Ordinal-Forest-Fit, comment = "", echo = FALSE}
# Display S and P ordinal forest object
ordfor_fit_sandp
```
The fitted model assigns a different level of importance to each of the indicator variables, as shown in the following table.
```{r Display-SandP-Ordinal-Forest-Importance, comment = "", echo = FALSE}
# Display S and P ordinal forest variable importance
ordfor_fit_sandp$varimp
```
The table indicates that *per_capita_gni* is the most important determinant of Standard and Poors sovereign credit ratings. 

The fitted ordinal forest model is next used to predict the Standard and Poors sovereign credit ratings based upon the randomized test set of indicators for each sovereign. The model calculates the probability of each credit rating category for each sovereign and its associated indicator values. The test set for the Standard and Poors model contains `r length(sandp_observations_test$country)` observations covering `r  length(unique(sandp_observations_test$country))` sovereigns across `r length(unique(sandp_observations_train$rating))` rating categories. The predicted ratings for the test set are compared to the actual test set ratings in the confusion matrix shown in Table \ref{tab:Generate-And-Display-SandP-Prediction-Counts}. A visualization of the confusion matrix is presented in Figure \@ref(fig:Plot-SandP-Ordinal-Forest-Mosaic).

```{r Predict-SandP-Ordinal-Forest-Ratings, echo = FALSE}
# Predict S and P ordinal forest ratings
sandp_observations_test_data <- sandp_observations_test %>% 
  dplyr::select(-c(country, year))
sandp_rating_predictions_ordinal_forest <- predict(ordfor_fit_sandp, newdata = sandp_observations_test_data)
```
```{r Generate-And-Display-SandP-Prediction-Counts, echo = FALSE}
# Produce S and P ordinal forest confusion matrix
sandp_observed_ratings_ordinal_forest <- factor(sandp_observations_test_data$rating, 
                                                levels = sandp_rating_categories, ordered = TRUE)
sandp_predicted_ratings_ordinal_forest <- factor(sandp_rating_predictions_ordinal_forest$ypred, 
                                                 levels = sandp_rating_categories, ordered = TRUE)
sandp_prediction_counts_ordinal_forest <- table(sandp_predicted_ratings_ordinal_forest, 
                                                sandp_observed_ratings_ordinal_forest)

sandp_ordinal_forest_tibble <- tibble(sandp_predicted_ratings_ordinal_forest, sandp_observed_ratings_ordinal_forest)

knitr::kable(sandp_prediction_counts_ordinal_forest, 
             caption = "Standard and Poors Ordinal Forest Model Confusion Matrix", 
             format = "latex", 
             booktabs = TRUE) %>% 
  kable_styling(latex_options = c("striped", "scale_down")) %>% 
    add_header_above(header = c("Actual Rating " = 1, "Predicted Rating" = dim(sandp_prediction_counts_ordinal_forest)[1] - 1))

```

```{r Plot-SandP-Ordinal-Forest-Mosaic, fig.cap = "Standard & Poors Ordinal Forest Model Prediction Mosaic", fig.height = 8, fig.width = 8, echo = FALSE}
# Produce S and P ordinal forest mosaic chart
mosaicplot(sandp_prediction_counts_ordinal_forest,
           main = "Standard & Poors Credit Ratings Mosaic Chart",
           color = c("slateblue", "slateblue1"),
           xlab = "Observed Rating", 
           ylab = "Predicted Rating")

```

#### Fitch Ordinal Forest Model

The Fitch ordinal forest model is trained using a subset comprised of `r length(fitch_observations_train$country)` observations. The observations cover ratings for `r length(unique(fitch_observations_train$country))` countries across `r  length(unique(fitch_observations_train$rating))` rating categories. The summary output from training this model is shown below.

```{r Fit-Fitch-Rating-Ordinal-Forest-Model, warnings = FALSE, message = FALSE, echo = FALSE}
# Fit Fitch ordinalforest model
fitch_observations_train_data <- fitch_observations_train %>% 
  dplyr::select(-c("country", "year"))
ordfor_fit_fitch <- ordfor(depvar = "rating", data = fitch_observations_train_data, 
                            nsets=100, ntreeperdiv=100, ntreefinal=500, 
                            perffunction = "probability")
```
```{r Display-Fitch-Ordinal-Forest-Fit, comment = "", echo = FALSE}
# Display Fitch ordinal forest object
ordfor_fit_fitch
```
The fitted model assigns a different level of importance to each of the indicator variables, as shown in the following table.
```{r Display-Fitch-Ordinal-Forest-Importance, comment = "", echo = FALSE}
# Display Fitch ordinal forest variable importance
ordfor_fit_fitch$varimp
```
The table indicates that *per_capita_gni* is the most important determinant of Fitch sovereign credit ratings. 

The fitted ordinal forest model is next used to predict the Fitch sovereign credit ratings based upon the randomized test set of indicators for each sovereign. The model calculates the probability of each credit rating category for each sovereign and its associated indicator values. The test set for the Fitch model contains `r length(fitch_observations_test$country)` observations covering `r  length(unique(fitch_observations_test$country))` sovereigns across `r length(unique(fitch_observations_train$rating))` rating categories. The predicted ratings for the test set are compared to the actual test set ratings in the confusion matrix shown in Table \ref{tab:Generate-And-Display-Fitch-Prediction-Counts}. A visualization of the confusion matrix is presented in Figure \@ref(fig:Plot-Fitch-Ordinal-Forest-Mosaic).

```{r Predict-Fitch-Ordinal-Forest-Ratings, echo = FALSE}
# Predict Fitch ordinal forest ratings
fitch_observations_test_data <- fitch_observations_test %>% 
  dplyr::select(-c(country, year))
fitch_rating_predictions_ordinal_forest <- predict(ordfor_fit_fitch, newdata = fitch_observations_test_data)
```
```{r Generate-And-Display-Fitch-Prediction-Counts, echo = FALSE}
# Produce Fitch ordinal forest confusion matrix
fitch_observed_ratings_ordinal_forest <- factor(fitch_observations_test_data$rating, 
                                                levels = fitch_rating_categories, ordered = TRUE)
fitch_predicted_ratings_ordinal_forest <- factor(fitch_rating_predictions_ordinal_forest$ypred, 
                                                 levels = fitch_rating_categories, ordered = TRUE)
fitch_prediction_counts_ordinal_forest <- table(fitch_predicted_ratings_ordinal_forest, 
                                                fitch_observed_ratings_ordinal_forest)

fitch_ordinal_forest_tibble <- tibble(fitch_predicted_ratings_ordinal_forest, fitch_observed_ratings_ordinal_forest)

knitr::kable(fitch_prediction_counts_ordinal_forest, 
             caption = "Fitch Ordinal Forest Model Confusion Matrix", 
             format = "latex", 
             booktabs = TRUE) %>% 
  kable_styling(latex_options = c("striped", "scale_down")) %>% 
    add_header_above(header = c("Actual Rating" = 1, "Predicted Rating" = dim(fitch_prediction_counts_ordinal_forest)[1] - 1))

```

```{r Plot-Fitch-Ordinal-Forest-Mosaic, fig.cap = "Fitch Ordinal Forest Model Prediction Mosaic", fig.height = 8, fig.width = 8, echo = FALSE}
# Produce Fitch ordinal forest mosaic chart
mosaicplot(fitch_prediction_counts_ordinal_forest,
           main = "Fitch Credit Ratings Mosaic Chart",
           color = c("slateblue", "slateblue1"),
           xlab = "Observed Rating", 
           ylab = "Predicted Rating")

```

### Linear Discriminant Analysis Models

The second ordinal classification modeling approach considered in this report is *Linear Discriminant Analysis* (LDA). LDA is a generalization of Fisher's linear discriminant, a method used in statistics and other fields, to find a linear combination of features that characterizes or separates two or more classes of objects or events. The resulting combination may be used as a linear classifier. Discriminant analysis works by creating one or more linear combinations of predictors, creating a new latent variable for each function. These functions are called discriminant functions. The number of functions possible is either $N_{g} - 1$, where $N_{g}$ is the number of groups, or $p$ (the number of predictors), whichever is smaller. The first function created maximizes the differences between groups on that function. The second function maximizes differences on that function, but also must not be correlated with the previous function. This continues with subsequent functions with the requirement that the new function not be correlated with any of the previous functions.

Given group $j$, with $R_{j}$ sets of sample space, there is a discriminant rule such that if $x \in R_j$, then $x \in j$. Discriminant analysis then, finds “good” regions of $R_j$ to minimize classification error, therefore leading to a high percent correct classified in the classification table. Each function is given a discriminant score to determine how well it predicts group placement:

  * Structure Correlation Coefficients: The correlation between each predictor and the discriminant score of each function. This is a zero-order correlation (i.e., not corrected for the other predictors).
  * Standardized Coefficients: Each predictor's weight in the linear combination that is the discriminant function. Like in a regression equation, these coefficients are partial (i.e., corrected for the other predictors). Indicates the unique contribution of each predictor in predicting group assignment.
  * Functions at Group Centroids: Mean discriminant scores for each grouping variable are given for each function. The farther apart the means are, the less error there will be in classification.

#### Moody's Linear Discriminant Analysis Model

The Moody's linear discriminant analysis model is trained using a subset comprised of `r length(moodys_observations_train$country)` observations. The observations cover ratings for `r length(unique(moodys_observations_train$country))` countries across `r  length(unique(moodys_observations_train$rating))` rating categories. The summary output from training this model is shown below.

```{r Fit-Moodys-LDA-Model, warning = FALSE, message = FALSE, echo = FALSE}
# Fit Moodys LDA model
lda_fit_moodys <- lda(rating ~ per_capita_gni + growth_gni + cpi_inflation + 
                      current_account_ratio + developing, 
                      data = moodys_observations_train_data)
```
Fitting the LDA model to Moody's observations produces the following results.
```{r Display-Moodys-LDA-Fit, comment = "", echo = FALSE}
# Display Moodys LDA object
lda_fit_moodys
```

The separation of observations into different subsets by the linear discriminant functions is shown in Figure \@ref(fig:Plot-Moodys-LDA-Fit).


```{r Plot-Moodys-LDA-Fit, fig.cap = "**Moody's Linear Discriminant Functions**", echo = FALSE}
# Plot Moodys LDA discriminant functions
plot(lda_fit_moodys)
```


The fitted linear discriminant model is next used to predict the Moody's sovereign credit ratings based upon the randomized test set of indicators for each sovereign. The model calculates the probability of each credit rating category for each sovereign and its associated indicator values. The test set for the Moody's model contains `r length(moodys_observations_test$country)` observations covering `r  length(unique(moodys_observations_test$country))` sovereigns across `r length(unique(moodys_observations_train$rating))` rating categories.  The predicted ratings for the test set are compared to the actual test set ratings in the confusion matrix shown in Table \ref{tab:Generate-And-Display-Moodys-Prediction-Counts-LDA}. A mosaic plot of the confusion matrix is presented in Figure \@ref(fig:Plot-Moodys-LDA-Mosaic).

```{r Predict-Moodys-LDA-Ratings, echo = FALSE}
# Predict Moodys LDA ratings
moodys_observations_test_data <- moodys_observations_test %>% 
  dplyr::select(-c(country, year))
moodys_rating_predictions_LDA <- predict(lda_fit_moodys, newdata = moodys_observations_test_data)
```
```{r Generate-And-Display-Moodys-Prediction-Counts-LDA, echo = FALSE}
# Produce and display Moodys LDA confusion matrix
moodys_observed_ratings_LDA <- factor(moodys_observations_test_data$rating, 
                                                 levels = moodys_rating_categories, ordered = TRUE)
moodys_predicted_ratings_LDA <- factor(moodys_rating_predictions_LDA$class, 
                                                  levels = moodys_rating_categories, ordered = TRUE)
moodys_prediction_counts_LDA <- table(moodys_predicted_ratings_LDA, 
                                                 moodys_observed_ratings_LDA)

moodys_LDA_tibble <- tibble(moodys_predicted_ratings_LDA, moodys_observed_ratings_LDA)

knitr::kable(moodys_prediction_counts_LDA, 
             caption = "Moody's Linear Discriminant Analysis Model Confusion Matrix", 
             format = "latex", 
             booktabs = TRUE) %>% 
  kable_styling(latex_options = c("striped", "scale_down")) %>% 
    add_header_above(header = c("Actual Rating " = 1, "Predicted Rating" = dim(moodys_prediction_counts_LDA)[1] - 1))

```

```{r Plot-Moodys-LDA-Mosaic, fig.cap = "Moody's Linear Discriminant Model Prediction Mosaic", fig.height = 8, fig.width = 8, echo = FALSE}
# Plot Moodys LDA mosaic chart
mosaicplot(moodys_prediction_counts_LDA,
           main = "Moody's Credit Ratings Mosaic Chart",
           color = c("slateblue", "slateblue1"),
           xlab = "Observed Rating", 
           ylab = "Predicted Rating")

```

#### Standard and Poors Linear Discriminant Analysis Model

The Standard and Poors linear discriminant analysis model is trained using a subset comprised of `r length(sandp_observations_train$country)` observations. The observations cover ratings for `r length(unique(sandp_observations_train$country))` countries across `r  length(unique(sandp_observations_train$rating))` rating categories. All of the observations in this subset are for developing countries, so the *developing* indicator is excluded from the training data. The summary output from training this model is shown below.

```{r Fit-Sandp-LDA-Model, warning = FALSE, message = FALSE, echo = FALSE}
# Fit S and P LDA model
lda_fit_sandp <- lda(rating ~ per_capita_gni + growth_gni + cpi_inflation + 
                      current_account_ratio + developing, 
                      data = sandp_observations_train_data)

```

Fitting the LDA model to Standard and Poors observations produces the following results.

```{r Display-SandP-LDA-Fit, comment = "", echo = FALSE}
# Display S and P LDA object
lda_fit_sandp
```

The separation of observations into different subsets by the linear discriminant functions is shown in Figure \@ref(fig:Plot-SandP-LDA-Fit).


```{r Plot-SandP-LDA-Fit, fig.cap = "**Standard and Poors Linear Discriminant Functions**", echo = FALSE}
# Plot S and P LDA discriminant functions
plot(lda_fit_sandp)
```


The fitted linear discriminant model is next used to predict the Standard and Poors sovereign credit ratings based upon the randomized test set of indicators for each sovereign. The model calculates the probability of each credit rating category for each sovereign and its associated indicator values. The test set for the Standard and Poors model contains `r length(sandp_observations_test$country)` observations covering `r  length(unique(sandp_observations_test$country))` sovereigns across `r length(unique(sandp_observations_train$rating))` rating categories.  The predicted ratings for the test set are compared to the actual test set ratings in the confusion matrix shown in Table \ref{tab:Generate-And-Display-SandP-Prediction-Counts-LDA}. A visualization of the confusion matrix is presented in Figure \@ref(fig:Plot-SandP-LDA-Mosaic).

```{r Predict-SandP-LDA-Ratings, echo = FALSE}
# Predict S and P LDA ratings
sandp_observations_test_data <- sandp_observations_test %>% 
  dplyr::select(-c(country, year))
sandp_rating_predictions_LDA <- predict(lda_fit_sandp, newdata = sandp_observations_test_data)
```
```{r Generate-And-Display-SandP-Prediction-Counts-LDA, echo = FALSE}
# Produce and display S and P LDA confusion matrix
sandp_observed_ratings_LDA <- factor(sandp_observations_test_data$rating, 
                                                 levels = sandp_rating_categories, ordered = TRUE)
sandp_predicted_ratings_LDA <- factor(sandp_rating_predictions_LDA$class, 
                                                  levels = sandp_rating_categories, ordered = TRUE)
sandp_prediction_counts_LDA <- table(sandp_predicted_ratings_LDA, 
                                                 sandp_observed_ratings_LDA)
                                     
sandp_LDA_tibble <- tibble(sandp_predicted_ratings_LDA, sandp_observed_ratings_LDA)

knitr::kable(sandp_prediction_counts_LDA, 
             caption = "Standard and Poors Linear Discriminant Analysis Model Confusion Matrix", 
             format = "latex", 
             booktabs = TRUE) %>% 
  kable_styling(latex_options = c("striped", "scale_down")) %>% 
    add_header_above(header = c("Actual Rating " = 1, "Predicted Rating" = dim(sandp_prediction_counts_LDA)[1] - 1))

```
```{r Plot-SandP-LDA-Mosaic, fig.cap = "Standard & Poors Linear Discriminant Model Prediction Mosaic", fig.height = 8, fig.width = 8, echo = FALSE}
# Plot S and P LDA mosaic chart
mosaicplot(sandp_prediction_counts_LDA,
           main = "Standard & Poors Credit Ratings Mosaic Chart",
           color = c("slateblue", "slateblue1"),
           xlab = "Observed Rating", 
           ylab = "Predicted Rating")

```

#### Fitch Linear Discriminant Analysis Model

The Fitch linear discriminant analysis model is trained using a subset comprised of `r length(fitch_observations_train$country)` observations. The observations cover ratings for `r length(unique(fitch_observations_train$country))` countries across `r  length(unique(fitch_observations_train$rating))` rating categories. All of the observations in this subset are for developing countries, so the *developing* indicator is excluded from the training data. The summary output from training this model is shown below.

```{r Fit-Fitch-LDA-Model, warning = FALSE, message = FALSE, echo = FALSE}
# Fit Fitch LDA model
lda_fit_fitch <- lda(rating ~ per_capita_gni + growth_gni + cpi_inflation + 
                      current_account_ratio, 
                      data = fitch_observations_train_data)

```
Fitting the LDA model to the Fitch observations produces the following results.

```{r Display-Fitch-LDA-Fit, comment = "", echo = FALSE}
# Display Fitch LDA object
lda_fit_fitch
```

The separation of observations into different subsets by the linear discriminant functions is shown in Figure \@ref(fig:Plot-Fitch-LDA-Fit).


```{r Plot-Fitch-LDA-Fit, fig.cap = "**Fitch Linear Discriminant Functions**", echo = FALSE}
# Plot Fitch LDA discriminant functions
plot(lda_fit_fitch)
```


The fitted linear discriminant model is next used to predict the Fitch sovereign credit ratings based upon the randomized test set of indicators for each sovereign. The model calculates the probability of each credit rating category for each sovereign and its associated indicator values. The test set for the Fitch model contains `r length(fitch_observations_test$country)` observations covering `r  length(unique(fitch_observations_test$country))` sovereigns across `r length(unique(fitch_observations_train$rating))` rating categories.  The predicted ratings for the test set are compared to the actual test set ratings in the confusion matrix shown in Table \ref{tab:Generate-And-Display-Fitch-Prediction-Counts-LDA}. A visualization of the confusion matrix is presented in Figure \@ref(fig:Plot-Fitch-LDA-Mosaic).

```{r Predict-Fitch-LDA-Ratings, echo = FALSE}
# Predict Fitch LDA ratings
fitch_observations_test_data <- fitch_observations_test %>% 
  dplyr::select(-c(country, year))
fitch_rating_predictions_LDA <- predict(lda_fit_fitch, newdata = fitch_observations_test_data)
```
```{r Generate-And-Display-Fitch-Prediction-Counts-LDA, echo = FALSE}
# Produce and display Fitch LDA confusion matrix
fitch_observed_ratings_LDA <- factor(fitch_observations_test_data$rating, 
                                                 levels = fitch_rating_categories, ordered = TRUE)
fitch_predicted_ratings_LDA <- factor(fitch_rating_predictions_LDA$class, 
                                                  levels = fitch_rating_categories, ordered = TRUE)
fitch_prediction_counts_LDA <- table(fitch_predicted_ratings_LDA, 
                                                 fitch_observed_ratings_LDA)

knitr::kable(fitch_prediction_counts_LDA, 
             caption = "Fitch Linear Discriminant Analysis Model Confusion Matrix", 
             format = "latex", 
             booktabs = TRUE) %>% 
  kable_styling(latex_options = c("striped", "scale_down")) %>% 
    add_header_above(header = c("Actual Rating " = 1, "Predicted Rating" = dim(fitch_prediction_counts_LDA)[1] - 1))

fitch_LDA_tibble <- tibble(fitch_predicted_ratings_LDA, fitch_observed_ratings_LDA)
```
```{r Plot-Fitch-LDA-Mosaic, fig.cap = "Fitch Linear Discriminant Model Prediction Mosaic", fig.height = 8, fig.width = 8, echo = FALSE}
# Plot Fitch LDA mosaic chart
mosaicplot(fitch_prediction_counts_LDA,
           main = "Fitch Credit Ratings Mosaic Chart",
           color = c("slateblue", "slateblue1"),
           xlab = "Observed Rating", 
           ylab = "Predicted Rating")

```


## Performance Measurement

Performance of classification models with $n$ categories is typically measured in terms of a confusion matrix $C = [c_{i,j}, i,j = 1,...n]$, where $i$ denotes the category of a predicted result, $j$ denotes the category of an actual result for an observation, and $c_{ij}$ is the number of observations where the predicted category is $i$ and the actual category is $j$. In the previous section of this report, Tables \ref{tab:Generate-And-Display-Moodys-Prediction-Counts-Ordinal-Forest} to \ref{tab:Generate-And-Display-Fitch-Prediction-Counts-LDA} presented confusion matrices for the six credit rating prediction models developed there.

There are several alternative measures for classification model performance. The traditional measure is *Percentage Observed Agreement*, or $P_{o}$, which is the proportion of the confusion matrix values where the predicted result is the same as the observed result relative to the sum of all confusion matrix values, i.e.,
$$P_{o} = (\sum_{i = 1}^n C_{i,i}) / (\sum_{i = 1}^n \sum_{j = 1}^n C_{i,j})$$
which is the sum of all counts along the diagonal of the confusion matrix divided by the sum of all counts in all entries in the confusion matrix. 

*Percentage Observed Agreement* is criticized due to its inability to take into account random or expected agreement by chance, which is the proportion of agreement that you would expect two raters to have based simply on chance. Cohen’s *kappa* is a commonly used measure of agreement that removes this chance agreement (see [@cohen]), because it accounts for the possibility that raters actually guess on at least some variables due to uncertainty. This is accomplished by including *Percentage Chance Agreement* in the measurement of rater agreement. *Percentage Chance Agreement*, or $P_{e}$, is the sum of the products of the rows and columns marginal proportions in the confusion matrix, i.e.
$$P_{e} = \sum_{i = 1}^k P_{i+} \cdot P_{+i}$$
where the row marginal proportion is
$$P_{i+} = \sum_{j = 1}^n C_{i,j} / (\sum_{i = 1}^n \sum_{j = 1}^n C_{i,j})$$
and the column marginal proportion is
$$P_{+i} = \sum_{i = 1}^n C_{i,j} / (\sum_{i = 1}^n \sum_{j = 1}^n C_{i,j})$$
Cohen's *kappa* is then calculated as
$$\kappa = \frac{P_{o} - P_{e}}{1 - P_{e}}$$
For large sample sizes, the standard error (SE) of $\kappa$ can be computed as follows (see [@fleiss-cohen-everitt])
$$SE_{\kappa} = \frac{P_{e} + P_{e}^2 + \sum_{i = 1}^n P_{i+}\cdot P_{+i}\cdot(P_{i+}+ P_{+i})}{{{(\sum_{i = 1}^n \sum_{j = 1}^n C_{i,j})}\cdot}(1-P_{e})^2}$$
and a $100\cdot(1 - \alpha)$ % confidence interval for $\kappa$ may be computed using the standard normal distribution as follows:
$$\kappa\pm Z_{\alpha/2}\cdot SE_{\kappa}$$

```{r Display-kappa-Strength, warning = FALSE, echo = FALSE}
# Display kappa strength table
Value_of_kappa <- c("< 0", "0.01 - 0.20", "0.21 - 0.40", "0.41 - 0.60", "0.61 - 0.80", "0.81 - 1.00") 
strength_of_agreement <- c("Poor", "Slight", "Fair", "Moderate", "Substantial", "Almost perfect")
agreement_table <- tibble(Value_of_kappa, strength_of_agreement)
names(agreement_table) <- c("Value of kappa", "Strength")

knitr::kable(agreement_table, 
             caption = "Kappa Statistic Strength of Agreement", 
             format = "latex", 
             booktabs = TRUE)

```


In many applications, there is more interest in the magnitude of $\kappa$ than in the statistical significance of $\kappa$. The classifications that have been suggested to interpret the strength of the agreement based on the Cohen’s *kappa* value (see [@landis-koch]) are shown in Table \@ref(tab:Display-kappa-Strength).

Cohen’s *kappa* only counts strict agreement, where the same rating category is assigned by both the rating agency and the rating model. It takes no account of the degree of disagreement, all disagreements are treated equally. This is most appropriate when you have nominal variables, but for ordinal rating scales it may preferable to give different weights to the disagreements depending on their magnitude. *weighted kappa*, also originally developed by Cohen, addresses this issue by using a weighting scheme to take into account the closeness of agreement between rating categories. This is only suitable in the situation where you have ordinal or ranked rating variables, such as credit rating categories.

To compute *weighted kappa*, weights are assigned to each element in the confusion matrix, where the element weights range from 0 to 1, with weight = 1 assigned to all diagonal cells, corresponding to where the observed ratings and the model ratings agree. *weighted kappa* is calculated based on *Percentage Weighted Observed Agreement* and *Percentage Expected Chance Agreement*. *Percentage Weighted Observed Agreement*, or $P_o^w$, is the sum of weighted proportions across all elements of the confusion matrix, i.e.
$$P_o^w = \sum_{1 = 1}^n \sum_{j = 1}^n W_{i,j}\cdot P_{i,j}$$
where $W_{i,j}$ is the weight assigned to each element $C_{i,j}$ of the confusion matrix, and 
$$P_{i,j} = C_{i,j}/ (\sum_{i = 1}^n \sum_{j = 1}^n C_{i,j})$$ 
is the proportion of observations associated with each element $C_{i,j}$ of the confusion matrix. *Percentage Expected Chance Agreement*, or $P_e^w$, is the sum of the weighted product of rows and columns marginal proportions, i.e.
$$P_e^w = \sum_{1 = 1}^n \sum_{j = 1}^n W_{i,j}\cdot P_{i+}\cdot P_{+i}$$
where $W_{i,j}$, $P_{i+}$, and $P_{+i}$ are defined above. *weighted kappa* is then calculated as
$$\kappa^w = \frac{P_{o}^w - P_{e}^w}{1 - P_{e}^w}$$
There are two commonly used weighting schemes for *weighted kappa*: i) linear weights with equal spacing between ratings (see [@cicchetti-allison]), and ii) quadratic weights with spacing proportional to the square of the deviation between ratings (see [@fleiss-cohen]). Linear weights are calculated as $W_{i,j} = 1 - (\mid i - j \mid) / (n - 1)$, and quadratic weights are calculated as $W_{i,j} = 1 - (\mid i - j \mid)^2 / (n - 1)$, where $\mid i - j \mid$ is the distance between rating categories $i$ and $j$.

The performance of credit rating prediction models can also be measured by additional metrics, including Kendall's W and Spearman's rank correlation coefficient.

Kendall's W (also known as Kendall's coefficient of concordance) is a non-parametric statistic that is also used to measure classification model performance. It is a normalization of the statistic of the Friedman test, and can be used for assessing agreement among different rating methods. Kendall's W ranges from 0 (no agreement) to 1 (complete agreement). If the test statistic W is 1, then all the raters have been unanimous, and each rater has assigned the same order to the ratings. If W is 0, then there is no overall trend of agreement among the raters, and their ratings may be regarded as essentially random. Intermediate values of W indicate a greater or lesser degree of unanimity among the various ratings.

Mathematically, Kendall's W is defined as follows. Suppose that observation $i$ is given the rank $r_{i,j}$ by rater number $j$, where there are in total $n$ observations and $m$ raters. Then the total rank given to observation $i$ is
$$R_{i} = \sum_{j = 1}^m r_{i, j}$$
and the mean value of these total ranks is
$$\overline{R}= \frac{1}{n}\sum_{j = 1}^m R_{i}$$
The sum of squared deviations, $S$, is defined as
$$S = \sum_{i = 1}^n (R_{i} - \overline{R})^{2}$$
and then Kendall's W is defined as
$$W = \frac{12 \cdot S}{m^2 \cdot (n^3 - n)}$$

In the case of complete ranks, a commonly used significance test for W against a null hypothesis of no agreement (i.e. random rankings) is given by 
$$\chi^2 = m\cdot(n - 1)\cdot W$$
where the test statistic takes a chi-squared distribution with $(n - 1)$ degrees of freedom.

Kendall's W is linearly related to the mean value of the Spearman's rank correlation coefficients between all $\left(\begin{array}{c}m\\ 2\end{array}\right)$ possible pairs of rankings between raters as follows
$$\overline{r_{s}} = \frac{mW - 1}{m - 1}$$
Thus, Spearman's rank correlation coefficient $\overline{r_{s}}$ can be computed from Kendall's W using this relationship. The statistical significance of $\overline{r_{s}}$ is obtained from the z-score for $\overline{r_{s}}$, which is
$$z = \sqrt{\frac{(n - 3)}{1.06}} \cdot F(\overline r_{s})$$
where $F(r_{s}) = arctanh(r_{s})$ is the Fisher transformation of $r_{s}$.

In the remainder of this section, the performance metrics outlined above are applied to each of the credit rating prediction models to determine the predictive power of the models.

```{r Define-Model-Performance-Function, echo = FALSE}
model_performance <- function(response_tibble) {
  agree_result <- agree(response_tibble)
  num_obs <- agree_result$subjects
  method_agree <- agree_result$method
  value_agree <- agree_result$value
  kappa_unweighted_result <- kappa2(response_tibble, weight = "unweighted")
  Kappa_unweighted_method <- kappa_unweighted_result$method
  kappa_unweighted_value <- kappa_unweighted_result$value
  kappa_unweighted_stat.name <- kappa_unweighted_result$stat.name
  kappa_unweighted_statistic <- kappa_unweighted_result$statistic
  kappa_unweighted_p.value <- kappa_unweighted_result$p.value
  kappa_equalweight_result <- kappa2(response_tibble, weight = "equal")
  kappa_equalweight_method <- kappa_equalweight_result$method
  kappa_equalweight_value <- kappa_equalweight_result$value
  kappa_equalweight_stat.name <- kappa_equalweight_result$stat.name
  kappa_equalweight_statistic <- kappa_equalweight_result$statistic
  kappa_equalweight_p.value <- kappa_equalweight_result$p.value
  kappa_squared_result <- kappa2(response_tibble, weight = "squared")
  Kappa_squared_method <- kappa_squared_result$method
  kappa_squared_value <- kappa_squared_result$value
  kappa_squared_stat.name <- kappa_squared_result$stat.name
  kappa_squared_statistic <- kappa_squared_result$statistic
  kappa_squared_p.value <- kappa_squared_result$p.value
  kendall_W_result <- kendall(response_tibble)
  kendall_W_method <- kendall_W_result$method
  kendall_W_value <- kendall_W_result$value
  kendall_W_stat.name <- kendall_W_result$stat.name
  kendall_W_statistic <- kendall_W_result$statistic
  kendall_W_p.value <- kendall_W_result$p.value 
  spearman_r_method <- "Spearman rank correllation coefficient r"
  spearman_r_value <- 2 * kendall_W_value - 1
  spearman_r_stat.name <- "z"
  spearman_r_statistic <- sqrt((num_obs - 3) / 1.06) * atanh(spearman_r_value)
  performance_methods <- c(method_agree, Kappa_unweighted_method, kappa_equalweight_method, 
                           Kappa_squared_method, kendall_W_method, spearman_r_method)
  performance_values <- c(value_agree, kappa_unweighted_value, kappa_equalweight_value, 
                          kappa_squared_value, kendall_W_value, spearman_r_value)
  performance_stat.names <- c("", kappa_unweighted_stat.name, kappa_equalweight_stat.name, 
                              kappa_squared_stat.name, kendall_W_stat.name, spearman_r_stat.name)
  performance_statistics <- c(NA, kappa_unweighted_statistic, kappa_equalweight_statistic, 
                              kappa_squared_statistic, kendall_W_statistic, spearman_r_statistic)
  performance_p.values <- c(NA, kappa_unweighted_p.value, kappa_equalweight_p.value, 
                            kappa_squared_p.value, kendall_W_p.value, NA)
  performnce_tibble <- tibble(Method = performance_methods, Value = performance_values, 
                              Stat.Name = performance_stat.names, Stat.Value = performance_statistics, 
                              P.value = performance_p.values)
  return(performnce_tibble)
}
```

### Ordinal Forest Model Performance

This section contains the model performance results for the ordinal forest models developed and applied in the previous section.

#### Moody's Ordinal Forest Model Performance

```{r Calculate-and-Display-Moodys-Ordinal-Forest-Model-Performance, echo = FALSE}
# Calculate and display Moodys ordinal forest model performance
moodys_ordinal_forest_model_performance <- model_performance(moodys_ordinal_forest_tibble)

knitr::kable(moodys_ordinal_forest_model_performance, 
             caption = "Moody's Ordinal Forest Model Performance", 
             format = "latex", 
             booktabs = TRUE) %>% 
  kable_styling(latex_options = c("striped", "scale_down"))

```


The performance results for the Moody's ordinal forest model are presented in Table \@ref(tab:Calculate-and-Display-Moodys-Ordinal-Forest-Model-Performance). This model has modest *Percentage Agreement*, consistent with the dispersion shown in the mosaic chart in Figure \@ref(fig:Plot-Moodys-Ordinal-Forest-Mosaic). The model also shows fair strength of agreement between predicted and observed ratings based on $\kappa$ values, and the z-statistics for the $\kappa$ values indicate that the predicted and observed ratings are drawn from the same populations. Kendall's coefficient of concordance $W$ indicates a high level of agreement between predicted and observed ratings, and the $\chi^2$ statistic and associated *p* value show that the null hypothesis that there is no agreement between predicted and observed ratings can be rejected. The Spearman rank correlation coefficient $\overline{r_{s}}$ indicates a moderate positive relationship between predicted and observed rating ranking.

#### Standard and Poors Ordinal Forest Model Performance

```{r Calculate-and-Display-SandP-Ordinal-Forest-Model-Performance, echo = FALSE} 
# Calculate and display S and P ordinal forest model performance
sandp_ordinal_forest_model_performance <- model_performance(sandp_ordinal_forest_tibble)

knitr::kable(sandp_ordinal_forest_model_performance, 
             caption = "Standard and Poors Ordinal Forest Model Performance", 
             format = "latex", 
             booktabs = TRUE) %>% 
  kable_styling(latex_options = c("striped", "scale_down"))

```


The performance results for the Standard and Poors ordinal forest model are presented in Table \@ref(tab:Calculate-and-Display-SandP-Ordinal-Forest-Model-Performance). This model has modest *Percentage Agreement*, consistent with the dispersion shown in the mosaic chart in Figure \@ref(fig:Plot-SandP-Ordinal-Forest-Mosaic). The model also shows moderate strength of agreement between predicted and observed ratings based on $\kappa$ values, and the z-statistics for the $\kappa$ values indicate that the predicted and observed ratings are drawn from the same populations. Kendall's coefficient of concordance $W$ indicates a high level of agreement between predicted and observed ratings, and the $\chi^2$ statistic and associated *p* value show that the null hypothesis that there is no agreement between predicted and observed ratings can be rejected. The Spearman rank correlation coefficient $\overline{r_{s}}$ indicates a moderate positive relationship between predicted and observed rating ranking.

#### Fitch Ordinal Forest Model Performance

```{r Calculate-and-Display-Fitch-Ordinal-Forest-Model-Performance, echo = FALSE} 
# Calculate and display Fitch ordinal forest model performance
fitch_ordinal_forest_model_performance <- model_performance(fitch_ordinal_forest_tibble)

knitr::kable(fitch_ordinal_forest_model_performance, 
             caption = "Fitch Ordinal Forest Model Performance", 
             format = "latex", 
             booktabs = TRUE) %>% 
  kable_styling(latex_options = c("striped", "scale_down"))

```


The performance results for the Fitch ordinal forest model are presented in Table \@ref(tab:Calculate-and-Display-Fitch-Ordinal-Forest-Model-Performance). This model has modest *Percentage Agreement*, consistent with the dispersion shown in the mosaic chart in Figure \@ref(fig:Plot-Fitch-Ordinal-Forest-Mosaic). The model also shows moderate strength of agreement between predicted and observed ratings based on $\kappa$ values, and the z-statistics for the $\kappa$ values indicate that the predicted and observed ratings are drawn from the same populations. Kendall's coefficient of concordance $W$ indicates a high level of agreement between predicted and observed ratings, and the $\chi^2$ statistic and associated *p* value show that the null hypothesis that there is no agreement between predicted and observed ratings can be rejected. The Spearman rank correlation coefficient $\overline{r_{s}}$ indicates a moderate positive relationship between predicted and observed rating ranking.

### Linear Discriminant Model Analysis Performance

This section contains the model performance results for the linear discriminant models developed and applied previously.

#### Moody's Linear Discriminant Analysis Model Performance

```{r Calculate-and-Display-Moodys-LDA-Model-Performance, echo = FALSE} 
# Calculate and display Moodys LDA model performance
moodys_LDA_model_performance <- model_performance(moodys_LDA_tibble)

knitr::kable(moodys_LDA_model_performance, 
             caption = "Moody's Linear Discriminant Analysis Model Performance", 
             format = "latex", 
             booktabs = TRUE) %>% 
  kable_styling(latex_options = c("striped", "scale_down"))
```


The performance results for the Moody's linear discriminant analysis model are presented in Table \@ref(tab:Calculate-and-Display-Moodys-LDA-Model-Performance). This model has modest *Percentage Agreement*, consistent with the dispersion shown in the mosaic chart in Figure \@ref(fig:Plot-Moodys-LDA-Mosaic). The model also shows fair strength of agreement between predicted and observed ratings based on $\kappa$ values, and the z-statistics for the $\kappa$ values indicate that the predicted and observed ratings are drawn from the same populations. Kendall's coefficient of concordance $W$ indicates a high level of agreement between predicted and observed ratings, and the $\chi^2$ statistic and associated *p* value show that the null hypothesis that there is no agreement between predicted and observed ratings can be rejected. The Spearman rank correlation coefficient $\overline{r_{s}}$ indicates a moderate positive relationship between predicted and observed rating ranking.

####  Standard and Poors Linear Discriminant Analysis Model Performance

```{r Calculate-and-Display-SandP-LDA-Model-Performance, echo = FALSE} 
# Calculate and display S and P LDA model performance
sandp_LDA_model_performance <- model_performance(sandp_LDA_tibble)

knitr::kable(sandp_LDA_model_performance, 
             caption = "Standard and Poors Linear Discriminant Analysis Model Performance", 
             format = "latex", 
             booktabs = TRUE) %>% 
  kable_styling(latex_options = c("striped", "scale_down"))
```


The performance results for the Standard and Poors linear discriminant analysis model are presented in Table \@ref(tab:Calculate-and-Display-SandP-LDA-Model-Performance). This model has modest *Percentage Agreement*, consistent with the dispersion shown in the mosaic chart in Figure \@ref(fig:Plot-SandP-LDA-Mosaic). The model also shows fair strength of agreement between predicted and observed ratings based on $\kappa$ values, and the z-statistics for the $\kappa$ values indicate that the predicted and observed ratings are drawn from the same populations. Kendall's coefficient of concordance $W$ indicates a high level of agreement between predicted and observed ratings, and the $\chi^2$ statistic and associated *p* value show that the null hypothesis that there is no agreement between predicted and observed ratings can be rejected. The Spearman rank correlation coefficient $\overline{r_{s}}$ indicates a low positive relationship between predicted and observed rating ranking.

####  Fitch Linear Discriminant Analysis Model Performance

```{r Calculate-and-Display-Fitch-LDA-Model-Performance, echo = FALSE} 
# Calculate and display  Fitch LDA model performance
fitch_LDA_model_performance <- model_performance(fitch_LDA_tibble)

knitr::kable(fitch_LDA_model_performance, 
             caption = "Fitch Linear Discriminant Analysis Model Performance", 
             format = "latex", 
             booktabs = TRUE) %>% 
  kable_styling(latex_options = c("striped", "scale_down"))

```


The performance results for the Fitch linear discriminant analysis model are presented in Table \@ref(tab:Calculate-and-Display-Fitch-LDA-Model-Performance). This model has modest *Percentage Agreement*, consistent with the dispersion shown in the mosaic chart in Figure \@ref(fig:Plot-Fitch-LDA-Mosaic). The model also shows fair strength of agreement between predicted and observed ratings based on $\kappa$ values, and the z-statistics for the $\kappa$ values indicate that the predicted and observed ratings are drawn from the same populations. Kendall's coefficient of concordance $W$ indicates a high level of agreement between predicted and observed ratings, and the $\chi^2$ statistic and associated *p* value show that the null hypothesis that there is no agreement between predicted and observed ratings can be rejected. The Spearman rank correlation coefficient $\overline{r_{s}}$ indicates a moderate positive relationship between predicted and observed rating ranking.


# Summary of Results and Conclusion

This report explored whether sovereign credit ratings by rating agencies can be predicted using current and historical economic and other data about each sovereign. Some economic and financial indicators that previous research indicated were relevant in predicting sovereign credit ratings were identified as potentially relevant to answering this question. Data for sovereign credit ratings and the economic and financial indicators was extracted from internet web sites to support the investigation, and a randomly-selected subset of this data was used to train two machine learning models for each rating agency. Each machine learning model was then used to predict sovereign credit ratings using a randomly-selected complementary subset of the data, and these predicted ratings for the complementaty subset were compared to observed ratings for this subset using confusion matrices and mosaic plots. Finally, various performance metrics for ordinal classification models were calculated to quantify the performance of each machine learning model.

The model performance results presented in the previous section show that both the ordinal forest and linear discriminant analysis models produce modest to moderate predictive performance measured by ordinal classification metrics such as Cohen $\kappa$, Kendall $W$, and average Spearman rank correlation $\overline{r_{s}}$ . The models have a relatively low ability to exactly predict the same rating category as assigned by the corresponding rating agency, e.g. the Moody's ordinal forest model frequently predicts another rating category when the rating agency assigns an "A1" rating to a sovereign. On the other hand, the models appear to have a strong capability to produce sovereign rating predictions that rank different sovereigns consistently when measured, e.g. by Kendall's coefficient of concordance $W$. Thus, the reliability of the sovereign credit rating predictions produced by the two machine learning models is somewhat mixed and depends upon whether exact predictions or consistent rankings of sovereigns are most useful.

Undoubtedly with further research better models with higher predictive performance can be developed. There are several areas where further research is likely to be productive. A large collection of current and historical economic, financial, and other indicators for sovereigns is available from a variety of sources, including the World Bank, the International Monetary Fund, the Bank for International Settlements, and others. Some of these indicators may have a stronger statistical relationship to sovereign credit ratings than the indicators used in this report, and their incorporation into a credit rating classification model might improve predictive performance. In exploring these additional indicators, the extent of sovereign coverage will be an important issue, particularly if the coverage is uneven accross sovereigns with different rating categories, as was the case with *external_debt_ratio* in this report. A related issue is whether gaps in sovereign coverage can be closed by finding supplementary sources for the missing data, e.g., an additional source for *external_debt_ratio* data, or by some interpolation or similar scheme that could generate the missing data.

Alternative machine learning models might also produce better predictive results. Since this report only applies ordinal forest and linear discriminant analysis models to the sovereign credit rating prediction problem, it only investigates a small portion of currently available machine learning models. Other ordinal classification models are available, and these models might provide a better means of predicting sovereign credit ratings. Some of these alternative models were investigated during the research for this report, but they were not pursued for various reasons.

# References




